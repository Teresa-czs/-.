{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06f37288-ea52-45b3-a695-035f9cde0f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ è½½æ•°æ®...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2074/1683348422.py:118: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  close_feats = close_prices.groupby('ISIN').apply(extract_close_features).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¸…æ´—ä¸ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆã€‚\n",
      "å¯æ˜ å°„äº¤æ˜“æ•°: 228913, ç¼ºå¤±user_idx: 0, ç¼ºå¤±asset_idx: 0\n",
      "æ„å»ºæ­£æ ·æœ¬...\n",
      "æ­£æ ·æœ¬: 89884, è´Ÿæ ·æœ¬: 359536\n",
      "Train æ ·æœ¬: 359536, Valid æ ·æœ¬: 89884\n",
      "DataLoader æ„å»ºå®Œæˆï¼štrain 703 æ‰¹æ¬¡ï¼Œvalid 176 æ‰¹æ¬¡\n",
      "Step 1 å®Œæˆã€‚å¯è¿›å…¥æ¨¡å‹å®šä¹‰é˜¶æ®µã€‚\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# xDeepFM å¤ç°é¡¹ç›® - Step 0 + Step 1\n",
    "# æ•°æ®é¢„å¤„ç† + è´Ÿé‡‡æ · + è®­ç»ƒé›†æ„å»º\n",
    "# ï¼ˆåœ¨ä¸æ”¹å˜è¯­ä¹‰/é‡‡æ ·æ¯”ä¾‹çš„å‰æä¸‹ï¼Œåšäº†å°‘é‡å·¥ç¨‹å¢å¼ºï¼‰\n",
    "# ================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -----------------------\n",
    "# åŸºç¡€é…ç½®ï¼ˆé›†ä¸­åˆ°ä¸€å¤„ï¼‰\n",
    "# -----------------------\n",
    "data_path = \"/workspace/FAR-Trans/FAR-Trans//\"\n",
    "FILES = {\n",
    "    'customers': os.path.join(data_path, \"customer_information.csv\"),\n",
    "    'assets': os.path.join(data_path, \"asset_information.csv\"),\n",
    "    'transactions': os.path.join(data_path, \"transactions.csv\"),\n",
    "    'markets': os.path.join(data_path, \"markets.csv\"),\n",
    "    'limit_prices': os.path.join(data_path, \"limit_prices.csv\"),\n",
    "    'close_prices': os.path.join(data_path, \"close_prices.csv\"),\n",
    "}\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 512\n",
    "NEG_SAMPLE_PER_POS = 4\n",
    "DYNAMIC_NEG = False  # â—å·²å…³é—­ï¼šä¸å†è¿›è¡ŒåŠ¨æ€è´Ÿé‡‡æ ·\n",
    "\n",
    "# ---- è®¾å¤‡ä¿¡æ¯ï¼ˆä»…ç”¨äº DataLoader ç¼ºçœè®¾å®šï¼‰\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IS_WINDOWS = (platform.system() == \"Windows\")\n",
    "\n",
    "# ---- éšæœºæ€§ä¸ç¨³å®šæ€§\n",
    "def set_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        import torch.backends.cudnn as cudnn\n",
    "        cudnn.benchmark = True\n",
    "        # å¦‚éœ€ç»å¯¹å¯å¤ç°ï¼šcudnn.deterministic = True; cudnn.benchmark = False\n",
    "\n",
    "set_seeds(SEED)\n",
    "\n",
    "# -----------------------\n",
    "# Step 0: æ•°æ®é¢„å¤„ç†\n",
    "# -----------------------\n",
    "print(\"åŠ è½½æ•°æ®...\")\n",
    "customers = pd.read_csv(FILES['customers'])\n",
    "assets = pd.read_csv(FILES['assets'])\n",
    "transactions = pd.read_csv(FILES['transactions'])\n",
    "markets = pd.read_csv(FILES['markets'])\n",
    "limit_prices = pd.read_csv(FILES['limit_prices'])\n",
    "close_prices = pd.read_csv(FILES['close_prices'])\n",
    "close_prices['timestamp'] = pd.to_datetime(close_prices['timestamp'])\n",
    "\n",
    "# ä»…ä¿ç•™ Buy äº¤æ˜“\n",
    "transactions = transactions[transactions['transactionType'] == 'Buy']\n",
    "\n",
    "# ç”¨æˆ·ä¸èµ„äº§æœ€æ–°è®°å½•\n",
    "customers_latest = customers.sort_values('timestamp').groupby('customerID').tail(1)\n",
    "assets_latest = assets.sort_values('timestamp').groupby('ISIN').tail(1)\n",
    "\n",
    "# èµ„äº§æ‰©å±•ç‰¹å¾ï¼ˆå« marketIDï¼‰\n",
    "assets_latest = assets_latest.merge(\n",
    "    markets[['marketID', 'country', 'marketClass', 'tradingHours']],\n",
    "    on='marketID', how='left'\n",
    ")\n",
    "assets_latest[['country', 'marketClass', 'tradingHours']] = (\n",
    "    assets_latest[['country', 'marketClass', 'tradingHours']].fillna('Unknown')\n",
    ")\n",
    "\n",
    "# limit_prices\n",
    "assets_latest = assets_latest.merge(\n",
    "    limit_prices[['ISIN', 'profitability', 'priceMinDate', 'priceMaxDate', 'minDate', 'maxDate']],\n",
    "    on='ISIN', how='left'\n",
    ")\n",
    "\n",
    "# æ•°å€¼å¤„ç†\n",
    "assets_latest['priceMinDate'] = pd.to_numeric(assets_latest['priceMinDate'], errors='coerce')\n",
    "assets_latest['priceMaxDate'] = pd.to_numeric(assets_latest['priceMaxDate'], errors='coerce')\n",
    "assets_latest['price_volatility_ratio'] = np.where(\n",
    "    assets_latest['priceMinDate'] != 0,\n",
    "    (assets_latest['priceMaxDate'] - assets_latest['priceMinDate']) / assets_latest['priceMinDate'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "assets_latest['minDate'] = pd.to_datetime(assets_latest['minDate'], errors='coerce')\n",
    "assets_latest['maxDate'] = pd.to_datetime(assets_latest['maxDate'], errors='coerce')\n",
    "assets_latest['listing_days'] = (assets_latest['maxDate'] - assets_latest['minDate']).dt.days\n",
    "\n",
    "# close_prices èšåˆ\n",
    "def extract_close_features(group):\n",
    "    group = group.sort_values('timestamp')\n",
    "    prices = group['closePrice'].values\n",
    "    if len(prices) < 2:\n",
    "        return pd.Series({'price_mean': np.nan, 'price_stability': np.nan,\n",
    "                          'max_drawdown': np.nan, 'recent_return': np.nan})\n",
    "    price_mean = prices.mean()\n",
    "    price_std = prices.std()\n",
    "    stability = price_std / price_mean if price_mean else np.nan\n",
    "    cum_max = np.maximum.accumulate(prices)\n",
    "    drawdowns = (prices / cum_max) - 1\n",
    "    max_dd = drawdowns.min()\n",
    "    recent_return = (prices[-1] - prices[max(-30, -len(prices))]) / prices[max(-30, -len(prices))]\n",
    "    return pd.Series({'price_mean': price_mean, 'price_stability': stability,\n",
    "                      'max_drawdown': max_dd, 'recent_return': recent_return})\n",
    "\n",
    "close_feats = close_prices.groupby('ISIN').apply(extract_close_features).reset_index()\n",
    "assets_latest = assets_latest.merge(close_feats, on='ISIN', how='left')\n",
    "\n",
    "# æ•°å€¼ç‰¹å¾å¤„ç†\n",
    "num_cols = ['profitability', 'price_volatility_ratio', 'listing_days',\n",
    "            'price_mean', 'price_stability', 'max_drawdown', 'recent_return']\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "assets_latest[num_cols] = imputer.fit_transform(assets_latest[num_cols])\n",
    "\n",
    "assets_latest['listing_days'] = np.log1p(assets_latest['listing_days'].clip(lower=0))\n",
    "assets_latest['recent_return'] = assets_latest['recent_return'].clip(-1, 1)\n",
    "assets_latest['max_drawdown'] = assets_latest['max_drawdown'].clip(-1, 0)\n",
    "assets_latest['price_volatility_ratio'] = assets_latest['price_volatility_ratio'].clip(0, 5)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "assets_latest[num_cols] = scaler.fit_transform(assets_latest[num_cols])\n",
    "\n",
    "# ç±»åˆ«ç¼–ç \n",
    "def encode_cols(df, cols):\n",
    "    encoders = {}\n",
    "    for c in cols:\n",
    "        df[c] = df[c].fillna('Unknown')\n",
    "        le = LabelEncoder()\n",
    "        df[c] = le.fit_transform(df[c].astype(str))\n",
    "        encoders[c] = le\n",
    "    return encoders\n",
    "\n",
    "user_cat_features = ['customerType', 'riskLevel', 'investmentCapacity']\n",
    "user_encoders = encode_cols(customers_latest, user_cat_features)\n",
    "\n",
    "asset_cat_features = ['assetCategory', 'assetSubCategory', 'marketID',\n",
    "                      'sector', 'industry', 'country', 'marketClass', 'tradingHours']\n",
    "asset_encoders = encode_cols(assets_latest, asset_cat_features)\n",
    "\n",
    "# ç”¨æˆ·ä¸èµ„äº§ç´¢å¼•\n",
    "user2idx = {u: i for i, u in enumerate(customers_latest['customerID'].unique())}\n",
    "asset2idx = {a: i for i, a in enumerate(assets_latest['ISIN'].unique())}\n",
    "customers_latest['user_idx'] = customers_latest['customerID'].map(user2idx)\n",
    "assets_latest['asset_idx'] = assets_latest['ISIN'].map(asset2idx)\n",
    "\n",
    "print(\"æ¸…æ´—ä¸ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆã€‚\")\n",
    "\n",
    "# -----------------------\n",
    "# Step 1: æ ·æœ¬æ„å»º + è´Ÿé‡‡æ · + æ•°æ®åˆ’åˆ†ï¼ˆéš¾è´Ÿé‡‡æ ·ï¼šåŒå¸‚åœºä¼˜å…ˆ + å…¨å±€å°‘é‡ï¼‰\n",
    "# -----------------------\n",
    "# æ˜ å°„ & è¿‡æ»¤\n",
    "transactions = transactions[\n",
    "    transactions['customerID'].isin(user2idx.keys()) &\n",
    "    transactions['ISIN'].isin(asset2idx.keys())\n",
    "].copy()\n",
    "transactions['user_idx'] = transactions['customerID'].map(user2idx)\n",
    "transactions['asset_idx'] = transactions['ISIN'].map(asset2idx)\n",
    "\n",
    "missing_users = transactions['user_idx'].isna().sum()\n",
    "missing_assets = transactions['asset_idx'].isna().sum()\n",
    "print(f\"å¯æ˜ å°„äº¤æ˜“æ•°: {len(transactions)}, ç¼ºå¤±user_idx: {missing_users}, ç¼ºå¤±asset_idx: {missing_assets}\")\n",
    "\n",
    "transactions = transactions.dropna(subset=['user_idx', 'asset_idx'])\n",
    "transactions['user_idx'] = transactions['user_idx'].astype(int)\n",
    "transactions['asset_idx'] = transactions['asset_idx'].astype(int)\n",
    "\n",
    "print(\"æ„å»ºæ­£æ ·æœ¬...\")\n",
    "pos_pairs = transactions[['user_idx', 'asset_idx']].drop_duplicates().copy()\n",
    "pos_pairs['label'] = 1\n",
    "\n",
    "num_users = len(user2idx)\n",
    "num_items = len(asset2idx)\n",
    "_rng = random.Random(SEED)  # å±€éƒ¨éšæœºæºï¼ˆä¸åŸç‰ˆä¸€è‡´ï¼‰\n",
    "\n",
    "# ====== ç¡¬è´Ÿé‡‡æ ·éœ€è¦çš„å¸‚åœºç´¢å¼•ï¼ˆæ¥è‡ªèµ„äº§ä¿¡æ¯æ–‡ä»¶ï¼‰ ======\n",
    "MARKET_RATIO = 0.9   # åŒå¸‚åœºæ¯”ä¾‹\n",
    "GLOBAL_RATIO = 0.1   # å…¨å±€éšæœºå°‘é‡æ¯”ä¾‹ï¼ˆè¡¥é½ï¼‰\n",
    "assert abs(MARKET_RATIO + GLOBAL_RATIO - 1.0) < 1e-6\n",
    "\n",
    "_asset_meta = assets_latest[['asset_idx', 'marketID']].dropna().copy()\n",
    "_asset_meta['asset_idx'] = _asset_meta['asset_idx'].astype(int)\n",
    "_asset_meta['marketID']  = _asset_meta['marketID'].astype(int)\n",
    "\n",
    "from collections import defaultdict\n",
    "_assets_by_market = defaultdict(set)\n",
    "for _, r in _asset_meta.iterrows():\n",
    "    _assets_by_market[int(r['marketID'])].add(int(r['asset_idx']))\n",
    "\n",
    "asset2market = dict(zip(_asset_meta['asset_idx'].tolist(), _asset_meta['marketID'].tolist()))\n",
    "_all_items_set = set(range(num_items))  # æ‰€æœ‰å¯ç”¨èµ„äº§ç´¢å¼•\n",
    "\n",
    "def _split_counts(total_needed: int, market_ratio: float):\n",
    "    mkt = int(round(total_needed * market_ratio))\n",
    "    rnd = total_needed - mkt\n",
    "    return mkt, rnd\n",
    "\n",
    "# ====== éš¾è´Ÿé‡‡æ ·ï¼ˆåŒå¸‚åœºä¼˜å…ˆ + å…¨å±€è¡¥é½ï¼›ä¸¥æ ¼è´Ÿä¾‹ï¼‰ ======\n",
    "def negative_sampling(pos_df, num_users, num_items, neg_per_pos=NEG_SAMPLE_PER_POS, rng_obj=_rng):\n",
    "    \"\"\"\n",
    "    ä¸åŸå‡½æ•°åŒç­¾åï¼Œä½†ç­–ç•¥æ”¹ä¸ºï¼š\n",
    "      - å¯¹æ¯ä¸ªç”¨æˆ· u çš„æ¯ä¸ªæ­£æ ·æœ¬èµ„äº§ aï¼š\n",
    "        å…ˆä» a æ‰€åœ¨ marketID çš„èµ„äº§é›†åˆä¸­é‡‡æœªäº¤äº’èµ„äº§ï¼ˆhard negativesï¼‰ï¼Œ\n",
    "        ä¸è¶³å†ä»å…¨å±€æœªäº¤äº’èµ„äº§è¡¥é½ï¼›\n",
    "      - å€™é€‰ä»…é™ _all_items_setï¼Œä¸”æ’é™¤ç”¨æˆ·å·²äº¤äº’é›†åˆï¼Œç¡®ä¿ä¸ºçœŸè´Ÿä¾‹ï¼›\n",
    "      - æ€»é‡ â‰ˆ æ¯ä¸ªæ­£æ ·æœ¬ neg_per_posï¼ˆè‹¥å€™é€‰ä¸è¶³åˆ™å°½é‡æ»¡è¶³ï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    pos_df = pos_df.astype({'user_idx': int, 'asset_idx': int})\n",
    "    user_pos = pos_df.groupby('user_idx')['asset_idx'].apply(set).to_dict()\n",
    "    neg_rows = []\n",
    "\n",
    "    for u, pos_set in user_pos.items():\n",
    "        if not pos_set:\n",
    "            continue\n",
    "\n",
    "        global_pool = list(_all_items_set - pos_set)\n",
    "        if not global_pool:\n",
    "            continue\n",
    "\n",
    "        for a in pos_set:\n",
    "            need_total = max(1, int(neg_per_pos))\n",
    "            need_mkt, _ = _split_counts(need_total, MARKET_RATIO)\n",
    "\n",
    "            mk_id = asset2market.get(int(a), None)\n",
    "            mk_pool = list(((_assets_by_market.get(mk_id, set())) & _all_items_set) - pos_set) if mk_id is not None else []\n",
    "\n",
    "            # å…ˆé‡‡åŒå¸‚åœº\n",
    "            take_mk = []\n",
    "            if need_mkt > 0 and mk_pool:\n",
    "                k = min(need_mkt, len(mk_pool))\n",
    "                take_mk = rng_obj.sample(mk_pool, k)\n",
    "\n",
    "            # ç”¨å…¨å±€è¡¥é½ï¼ˆå‰”é™¤å·²äº¤äº’ + å·²é€‰ï¼‰\n",
    "            already = set(take_mk) | pos_set\n",
    "            rnd_pool = list(set(global_pool) - already)\n",
    "            left = need_total - len(take_mk)\n",
    "            take_rnd = []\n",
    "            if left > 0 and rnd_pool:\n",
    "                k = min(left, len(rnd_pool))\n",
    "                take_rnd = rng_obj.sample(rnd_pool, k)\n",
    "\n",
    "            sampled = take_mk + take_rnd\n",
    "\n",
    "            # è‹¥ä»ä¸è¶³ï¼ˆæç«¯å°é›†åˆï¼‰ï¼Œå†ä»å…¨å±€è¡¥\n",
    "            if len(sampled) < need_total:\n",
    "                extra_pool = list(set(global_pool) - set(sampled))\n",
    "                if extra_pool:\n",
    "                    k = min(need_total - len(sampled), len(extra_pool))\n",
    "                    sampled += rng_obj.sample(extra_pool, k)\n",
    "\n",
    "            neg_rows.extend([(u, i) for i in sampled])\n",
    "\n",
    "    neg_df = pd.DataFrame(neg_rows, columns=['user_idx', 'asset_idx'])\n",
    "    neg_df['label'] = 0\n",
    "    return neg_df\n",
    "\n",
    "def build_train_dataframe(pos_df, num_users, num_items, neg_per_pos=NEG_SAMPLE_PER_POS):\n",
    "    neg_df = negative_sampling(pos_df, num_users, num_items, neg_per_pos)\n",
    "    data_df = pd.concat([pos_df, neg_df], axis=0, ignore_index=True)\n",
    "    data_df = data_df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "    return data_df\n",
    "\n",
    "data_df = build_train_dataframe(pos_pairs, num_users, num_items, NEG_SAMPLE_PER_POS)\n",
    "print(f\"æ­£æ ·æœ¬: {len(pos_pairs)}, è´Ÿæ ·æœ¬: {len(data_df) - len(pos_pairs)}\")\n",
    "\n",
    "user_feat_df = customers_latest.set_index('user_idx')[user_cat_features].copy()\n",
    "asset_feat_df = assets_latest.set_index('asset_idx')[asset_cat_features + num_cols].copy()\n",
    "\n",
    "data_df = (\n",
    "    data_df\n",
    "    .merge(user_feat_df, left_on='user_idx', right_index=True, how='left')\n",
    "    .merge(asset_feat_df, left_on='asset_idx', right_index=True, how='left')\n",
    ")\n",
    "\n",
    "assert data_df[user_cat_features + asset_cat_features + num_cols].isna().sum().sum() == 0, \\\n",
    "    \"ä»æœ‰ç¼ºå¤±å€¼ï¼Œè¯·æ£€æŸ¥é¢„å¤„ç†ã€‚\"\n",
    "\n",
    "train_df, valid_df = train_test_split(\n",
    "    data_df,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=data_df['label']\n",
    ")\n",
    "print(f\"Train æ ·æœ¬: {len(train_df)}, Valid æ ·æœ¬: {len(valid_df)}\")\n",
    "\n",
    "# -----------------------\n",
    "# Dataset / DataLoader\n",
    "# -----------------------\n",
    "class FARTransDataset(Dataset):\n",
    "    def __init__(self, df, user_cat_cols, asset_cat_cols, asset_num_cols):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.user_cat_cols = user_cat_cols\n",
    "        self.asset_cat_cols = asset_cat_cols\n",
    "        self.asset_num_cols = asset_num_cols\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        user_idx = torch.tensor(row['user_idx'], dtype=torch.long)\n",
    "        asset_idx = torch.tensor(row['asset_idx'], dtype=torch.long)\n",
    "        user_cat = torch.tensor(row[self.user_cat_cols].values.astype(np.int64))\n",
    "        asset_cat = torch.tensor(row[self.asset_cat_cols].values.astype(np.int64))\n",
    "        asset_num = torch.tensor(row[self.asset_num_cols].values.astype(np.float32))\n",
    "        label = torch.tensor(row['label'], dtype=torch.float32)\n",
    "        return user_idx, user_cat, asset_idx, asset_cat, asset_num, label\n",
    "\n",
    "# ---- é€šç”¨ DataLoader å·¥å‚ï¼ˆGPU å‹å¥½ï¼ŒCPU ä¿å®ˆï¼‰\n",
    "def make_loader(dataset, batch_size, shuffle,\n",
    "                num_workers: int = 0,\n",
    "                pin_memory: bool = False,\n",
    "                persistent_workers: bool = False,\n",
    "                prefetch_factor: int | None = None):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        persistent_workers=persistent_workers if num_workers > 0 else False,\n",
    "        prefetch_factor=(prefetch_factor if (prefetch_factor and num_workers > 0) else None),\n",
    "    )\n",
    "\n",
    "# ä¿æŒåŸè¡Œä¸ºï¼ˆCPU ä¿å®ˆå‚æ•°ï¼‰\n",
    "train_dataset = FARTransDataset(train_df, user_cat_features, asset_cat_features, num_cols)\n",
    "valid_dataset = FARTransDataset(valid_df, user_cat_features, asset_cat_features, num_cols)\n",
    "train_loader = make_loader(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "valid_loader = make_loader(valid_dataset, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"DataLoader æ„å»ºå®Œæˆï¼štrain {len(train_loader)} æ‰¹æ¬¡ï¼Œvalid {len(valid_loader)} æ‰¹æ¬¡\")\n",
    "\n",
    "# âŒ å·²åˆ é™¤ï¼šåŠ¨æ€è´Ÿé‡‡æ ·æŒ‚é’©ï¼ˆrebuild_train_loader_for_epochï¼‰ä¸ POS_PAIRS_TRAIN\n",
    "print(\"Step 1 å®Œæˆã€‚å¯è¿›å…¥æ¨¡å‹å®šä¹‰é˜¶æ®µã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9fed547-3226-4790-83c1-806962074032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== xDeepFM æ¨¡å‹æ„å»ºå®Œæˆ ====\n",
      "è®¾å¤‡: cuda\n",
      "Embed ç»´åº¦: 16\n",
      "Field æ•°é‡: 2(ID) + 3(UserCat) + 8(AssetCat) + 7(AssetNum) = 20\n",
      "CIN å±‚: [16, 16] -> è¾“å‡ºç»´åº¦ 32\n",
      "DNN ç»“æ„: [128, 64]\n",
      "å¯è®­ç»ƒå‚æ•°é‡: 543,905\n"
     ]
    }
   ],
   "source": [
    "## step2ç¬¬äºŒæ¬¡è°ƒæ•´\n",
    "# ================================\n",
    "# Step 2: çœŸå® 2 å±‚ CIN + xDeepFM æ¨¡å‹ï¼ˆç¨³å®šå¢å¼ºç‰ˆï¼‰\n",
    "# - CIN æ¯å±‚ BatchNorm1d + GELUï¼ˆé˜²é€šé“çˆ†ç‚¸ï¼‰\n",
    "# - DNN: Linear + LayerNorm + GELU + Dropoutï¼ˆå¯¹ç¨€ç–æ›´ç¨³ï¼‰\n",
    "# - EmbeddingDropout é»˜è®¤ 0.05ï¼ˆå¯å…³ï¼‰\n",
    "# - è¾“å‡ºå±‚ bias å¯ç”¨æ­£ä¾‹åŸºå‡†ç‡åˆå§‹åŒ–ï¼ˆå†·å¯åŠ¨æ›´ç¨³ï¼‰\n",
    "# - logits ææ€§å¼€å…³ logit_signï¼ŒAUC<0.5 æ—¶å¯ä¸€è¡Œç¿»è½¬\n",
    "# ================================\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ===== ç¨³å®šé»˜è®¤è¶…å‚ï¼ˆå¯¹é½å‹å¥½ + å®¹é‡æ”¶æ•›ï¼‰ =====\n",
    "EMBED_DIM  = 16          # 16 ä¾¿äº bf16/fp16 å¯¹é½\n",
    "CIN_SIZES  = [16, 16]    # ç¨³èµ·æ­¥ï¼Œç¨³å®šåå¯å‡åˆ° [32, 32]\n",
    "DNN_HIDDEN = [128, 64]\n",
    "DROPOUT    = 0.35\n",
    "EMB_DROPOUT_DEFAULT = 0.10  # è½»åº¦éšæœºåŒ– embï¼Œæ›´ç¨³\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- è½»é‡ EmbeddingDropout é’©å­ ----------\n",
    "class EmbeddingDropout(nn.Module):\n",
    "    def __init__(self, p: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.p = float(p)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.training or self.p <= 0.0:\n",
    "            return x\n",
    "        # x: (B, F, D)ï¼Œé€å…ƒç´  dropout\n",
    "        return F.dropout(x, p=self.p, training=True)\n",
    "\n",
    "class RealCIN(nn.Module):\n",
    "    \"\"\"\n",
    "    çœŸå®çš„ CINï¼ˆCompressed Interaction Networkï¼‰\n",
    "    è¾“å…¥: x å½¢çŠ¶ [B, F, D]\n",
    "    è¿‡ç¨‹: X_{k-1} ä¸ X_0 å¤–ç§¯ -> 1x1 Conv èšåˆ -> (B, H_k, D)\n",
    "    è¾“å‡º: æ‹¼æ¥æ¯å±‚å¯¹ D æ±‚å’Œåçš„ (B, sum(H_k))\n",
    "    \"\"\"\n",
    "    def __init__(self, field_num: int, embed_dim: int, layer_sizes):\n",
    "        super().__init__()\n",
    "        self.field_nums = [field_num]\n",
    "        self.embed_dim = embed_dim\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns   = nn.ModuleList()  # âœ¨ æ¯å±‚åš BN æŠ‘åˆ¶é€šé“å°ºåº¦æ¼‚ç§»\n",
    "        for size in layer_sizes:\n",
    "            in_channels = self.field_nums[-1] * self.field_nums[0]\n",
    "            self.convs.append(nn.Conv1d(in_channels=in_channels,\n",
    "                                        out_channels=size, kernel_size=1, bias=False))\n",
    "            self.bns.append(nn.BatchNorm1d(size))\n",
    "            self.field_nums.append(size)\n",
    "\n",
    "    def forward(self, x):  # x: (B, F0, D)\n",
    "        x0 = x\n",
    "        xs = [x]\n",
    "        outputs = []\n",
    "        for conv, bn in zip(self.convs, self.bns):\n",
    "            # å¤–ç§¯: (B, F_{k-1}, F0, D)\n",
    "            z = torch.einsum('bfd,bhd->bfhd', xs[-1], x0)\n",
    "            B, Fk_1, F0, D = z.size()\n",
    "            z = z.reshape(B, Fk_1 * F0, D).contiguous()  # (B, C_in, L=D)\n",
    "            z = conv(z)                                  # (B, H_k, D)\n",
    "            z = bn(z)\n",
    "            z = F.gelu(z)\n",
    "            outputs.append(z.sum(dim=2))                 # (B, H_k)\n",
    "            xs.append(z)                                 # (B, H_k, D)\n",
    "        return torch.cat(outputs, dim=1) if outputs else torch.zeros(x.size(0), 0, device=x.device)\n",
    "\n",
    "class XDeepFM(nn.Module):\n",
    "    \"\"\"\n",
    "    xDeepFMï¼ˆCIN + DNNï¼‰ï¼š\n",
    "    - user_idx / asset_idx å„ä¸€ä¸ª Embeddingï¼ˆIDåŸŸï¼‰\n",
    "    - ç”¨æˆ·/èµ„äº§ç±»åˆ«ç‰¹å¾ï¼šæ¯åˆ—ä¸€ä¸ª Embedding\n",
    "    - æ•°å€¼ç‰¹å¾ï¼šæ¯åˆ—ä¸€ä¸ª Linear(1->D)ï¼Œä½œä¸ºç‹¬ç«‹ field\n",
    "    - CIN æ˜¾å¼äº¤äº’ + DNN éšå¼äº¤äº’ -> æ‹¼æ¥è¾“å‡º logits\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_num: int,\n",
    "        asset_num: int,\n",
    "        embed_dim: int,\n",
    "        user_feats_sizes: list,   # æ¯ä¸ªç”¨æˆ·ç±»ç›®çš„ vocab size\n",
    "        asset_feats_sizes: list,  # æ¯ä¸ªèµ„äº§ç±»ç›®çš„ vocab size\n",
    "        asset_num_feat_dim: int,  # æ•°å€¼ç‰¹å¾åˆ—æ•°\n",
    "        cin_sizes = CIN_SIZES,\n",
    "        dnn_hidden = DNN_HIDDEN,\n",
    "        dropout = DROPOUT,\n",
    "        emb_dropout: float = EMB_DROPOUT_DEFAULT,\n",
    "        base_pos_rate: float | None = None,  # ç”¨æ­£ä¾‹åŸºå‡†ç‡åˆå§‹åŒ–è¾“å‡º bias\n",
    "        logit_sign: int = 1,                 # âœ¨ ææ€§å¼€å…³ï¼š-1 å¯æ•´ä½“å–å\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim  = embed_dim\n",
    "        self.logit_sign = 1 if logit_sign >= 0 else -1\n",
    "\n",
    "        # ID Embeddings\n",
    "        self.user_emb  = nn.Embedding(user_num, embed_dim)\n",
    "        self.asset_emb = nn.Embedding(asset_num, embed_dim)\n",
    "\n",
    "        # Categorical Embeddings\n",
    "        self.user_cat_embs  = nn.ModuleList([nn.Embedding(v, embed_dim) for v in user_feats_sizes])\n",
    "        self.asset_cat_embs = nn.ModuleList([nn.Embedding(v, embed_dim) for v in asset_feats_sizes])\n",
    "\n",
    "        # Numeric -> Embedding\n",
    "        self.asset_num_projs = nn.ModuleList([nn.Linear(1, embed_dim) for _ in range(asset_num_feat_dim)])\n",
    "\n",
    "        # field æ€»æ•°\n",
    "        self.field_num = 2 + len(user_feats_sizes) + len(asset_feats_sizes) + asset_num_feat_dim\n",
    "\n",
    "        # CINï¼ˆæ˜¾å¼äº¤äº’ï¼‰\n",
    "        self.cin = RealCIN(field_num=self.field_num, embed_dim=embed_dim, layer_sizes=cin_sizes)\n",
    "        cin_out_dim = sum(cin_sizes)\n",
    "\n",
    "        # DNNï¼ˆéšå¼äº¤äº’ï¼‰ï¼šLinear + LayerNorm + GELU + Dropout\n",
    "        dnn_in_dim = self.field_num * embed_dim\n",
    "        dnn_layers = []\n",
    "        in_dim = dnn_in_dim\n",
    "        for h in dnn_hidden:\n",
    "            dnn_layers += [nn.Linear(in_dim, h), nn.LayerNorm(h), nn.GELU(), nn.Dropout(dropout)]\n",
    "            in_dim = h\n",
    "        self.dnn = nn.Sequential(*dnn_layers)\n",
    "\n",
    "        # Embedding Dropout\n",
    "        self.emb_dropout = EmbeddingDropout(p=emb_dropout)\n",
    "\n",
    "        # è¾“å‡ºå±‚\n",
    "        self.output = nn.Linear(cin_out_dim + dnn_hidden[-1], 1)\n",
    "\n",
    "        self._reset_params(base_pos_rate)\n",
    "\n",
    "    def _reset_params(self, base_pos_rate: float | None):\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.asset_emb.weight)\n",
    "        for emb in self.user_cat_embs:  nn.init.xavier_uniform_(emb.weight)\n",
    "        for emb in self.asset_cat_embs: nn.init.xavier_uniform_(emb.weight)\n",
    "        for proj in self.asset_num_projs:\n",
    "            nn.init.xavier_uniform_(proj.weight); nn.init.zeros_(proj.bias)\n",
    "        for m in self.dnn:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)\n",
    "        nn.init.xavier_uniform_(self.output.weight)\n",
    "        if base_pos_rate is not None and 0.0 < base_pos_rate < 1.0:\n",
    "            with torch.no_grad():\n",
    "                bias = math.log(base_pos_rate / (1.0 - base_pos_rate))\n",
    "                self.output.bias.fill_(bias)   # å†·å¯åŠ¨æ›´ç¨³\n",
    "        else:\n",
    "            nn.init.zeros_(self.output.bias)\n",
    "\n",
    "    def forward(self, user_idx, user_cat_feats, asset_idx, asset_cat_feats, asset_num_feats):\n",
    "        \"\"\"\n",
    "        è¾“å…¥:\n",
    "          user_idx:   (B,)\n",
    "          user_cat:   (B, Uc)\n",
    "          asset_idx:  (B,)\n",
    "          asset_cat:  (B, Ac)\n",
    "          asset_num:  (B, An)\n",
    "        è¿”å›:\n",
    "          logits:     (B,)\n",
    "        \"\"\"\n",
    "        B = user_idx.size(0)\n",
    "\n",
    "        # ID åŸŸ\n",
    "        user_e  = self.user_emb(user_idx).unsqueeze(1)    # (B, 1, D)\n",
    "        asset_e = self.asset_emb(asset_idx).unsqueeze(1)  # (B, 1, D)\n",
    "\n",
    "        # ç±»åˆ«åŸŸ\n",
    "        user_cat_list  = [emb(user_cat_feats[:, i]).unsqueeze(1)  for i, emb in enumerate(self.user_cat_embs)]\n",
    "        asset_cat_list = [emb(asset_cat_feats[:, i]).unsqueeze(1) for i, emb in enumerate(self.asset_cat_embs)]\n",
    "\n",
    "        # æ•°å€¼åŸŸ\n",
    "        asset_num_feats = asset_num_feats.contiguous()\n",
    "        asset_num_list = [proj(asset_num_feats[:, i:i+1]).unsqueeze(1) for i, proj in enumerate(self.asset_num_projs)]\n",
    "\n",
    "        # æ‹¼æ¥ + EmbeddingDropout\n",
    "        x = torch.cat([user_e, asset_e] + user_cat_list + asset_cat_list + asset_num_list, dim=1)  # (B, F, D)\n",
    "        x = self.emb_dropout(x).contiguous()\n",
    "\n",
    "        # CIN æ˜¾å¼äº¤äº’\n",
    "        cin_out = self.cin(x)  # (B, sum(CIN_SIZES))\n",
    "\n",
    "        # DNN éšå¼äº¤äº’\n",
    "        x_flat = x.reshape(B, -1).contiguous()\n",
    "        dnn_out = self.dnn(x_flat) # (B, dnn_hidden[-1])\n",
    "\n",
    "        # æ‹¼æ¥è¾“å‡º\n",
    "        logits = self.output(torch.cat([cin_out, dnn_out], dim=1)).squeeze(1)  # (B,)\n",
    "        return self.logit_sign * logits\n",
    "\n",
    "# -------------------------------\n",
    "# æ„å»ºæ¨¡å‹å®ä¾‹ï¼ˆä¿æŒä½ çš„å¤–éƒ¨æ•°æ®ç»“æ„ï¼‰\n",
    "# -------------------------------\n",
    "import pandas as pd  # è‹¥ä½ çš„ç¯å¢ƒé‡Œå·²æœ‰ï¼Œå°±ä¸å¿…é‡å¤å¯¼\n",
    "\n",
    "def _get_vocab_sizes(df: pd.DataFrame, cols: list) -> list:\n",
    "    # vocab size = max(index) + 1ï¼›LabelEncoder ç”Ÿæˆçš„æ˜¯ 0..K-1\n",
    "    return [int(df[c].max()) + 1 for c in cols]\n",
    "\n",
    "user_feats_sizes = _get_vocab_sizes(customers_latest, user_cat_features)\n",
    "asset_feats_sizes = _get_vocab_sizes(assets_latest, asset_cat_features)\n",
    "\n",
    "user_num = len(user2idx)\n",
    "asset_num = len(asset2idx)\n",
    "asset_num_feat_dim = len(num_cols)\n",
    "\n",
    "model = XDeepFM(\n",
    "    user_num=user_num,\n",
    "    asset_num=asset_num,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    user_feats_sizes=user_feats_sizes,\n",
    "    asset_feats_sizes=asset_feats_sizes,\n",
    "    asset_num_feat_dim=asset_num_feat_dim,\n",
    "    cin_sizes=CIN_SIZES,\n",
    "    dnn_hidden=DNN_HIDDEN,\n",
    "    dropout=DROPOUT,\n",
    "    emb_dropout=EMB_DROPOUT_DEFAULT,\n",
    "    base_pos_rate=None,  # è‹¥çŸ¥é“æ­£ä¾‹æ¯”ä¾‹ pï¼Œå¡« pï¼ˆå¦‚ 0.12ï¼‰\n",
    "    logit_sign=1,        # è‹¥â€œflipped AUCâ€æ›´é«˜ï¼Œæ”¹ä¸º -1\n",
    ").to(DEVICE)\n",
    "\n",
    "# ---------- å‚æ•°åˆ†ç»„ helperï¼šembedding vs others ----------\n",
    "def get_param_groups_for_adamw(model: nn.Module):\n",
    "    \"\"\"\n",
    "    è¿”å›ä¸¤ä¸ª param ç»„ï¼Œä¾¿äºè®­ç»ƒæ—¶ï¼š\n",
    "      - å¯¹ embedding ç±»å‚æ•°è®¾ weight_decay=0.0\n",
    "      - å…¶å®ƒå±‚ç”¨å…¨å±€ weight_decay\n",
    "    \"\"\"\n",
    "    emb_params, other_params = [], []\n",
    "    for name, p in model.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "        if ('emb' in name) or ('Embedding' in p.__class__.__name__):\n",
    "            emb_params.append(p)\n",
    "        else:\n",
    "            other_params.append(p)\n",
    "    return emb_params, other_params\n",
    "\n",
    "def count_params(m):\n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"==== xDeepFM æ¨¡å‹æ„å»ºå®Œæˆ ====\")\n",
    "print(f\"è®¾å¤‡: {DEVICE}\")\n",
    "print(f\"Embed ç»´åº¦: {EMBED_DIM}\")\n",
    "print(f\"Field æ•°é‡: 2(ID) + {len(user_cat_features)}(UserCat) + {len(asset_cat_features)}(AssetCat) + {len(num_cols)}(AssetNum) = {model.field_num}\")\n",
    "print(f\"CIN å±‚: {CIN_SIZES} -> è¾“å‡ºç»´åº¦ {sum(CIN_SIZES)}\")\n",
    "print(f\"DNN ç»“æ„: {DNN_HIDDEN}\")\n",
    "print(f\"å¯è®­ç»ƒå‚æ•°é‡: {count_params(model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5eaa054b-d1b4-4b48-981b-251f04a58c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device] cuda; AMP=True\n",
      "âœ… torch.compile enabled (reduce-overhead)\n",
      "[DataLoader] multiprocess ON: workers=8, persistent=False, prefetch=1, start_method=fork\n",
      "[ClassStats] pos=1044, neg=4076, pos_weightâ‰ˆ3.90\n",
      "å¼€å§‹è®­ç»ƒï¼šEPOCHS=2, BATCH_SIZE=512, workers=8, pin=True, persistent=False\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] TrainLoss=0.94918 | ValidLoss=0.86766 | AUC=0.88981 | LogLoss=0.51395\n",
      "ğŸŸ¢ New best (auc): save -> xdeepfm_best.pt\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 02] TrainLoss=0.86179 | ValidLoss=0.85527 | AUC=0.89862 | LogLoss=0.50402\n",
      "ğŸŸ¢ New best (auc): save -> xdeepfm_best.pt\n",
      "\n",
      "âœ… è®­ç»ƒå®Œæˆï¼›æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨ xdeepfm_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 3: è®­ç»ƒå¾ªç¯ï¼ˆå¯è°ƒæ•´ä¸ºå¤šè¿›ç¨‹åŠ é€Ÿï¼‰\n",
    "# - AMP + TF32 + torch.compile\n",
    "# - DataLoader åœ¨ Notebook/Linux ä¼˜å…ˆä½¿ç”¨ forkï¼Œå°‘é‡ worker æ›´ç¨³\n",
    "# - Windows è‡ªåŠ¨é™çº§å•è¿›ç¨‹\n",
    "# ================================\n",
    "import os, gc, sys, math, platform, numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "EPOCHS = 2\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "GRAD_CLIP_NORM = 5.0\n",
    "BEST_PATH = \"xdeepfm_best.pt\"\n",
    "\n",
    "MONITOR = \"auc\"; MODE = \"max\"\n",
    "EARLY_STOP = True\n",
    "PATIENCE = 2\n",
    "MIN_DELTA = 5e-4\n",
    "\n",
    "USE_SCHED = True\n",
    "LR_MIN = 1e-5\n",
    "SCHED_CFG = dict(\n",
    "    mode='max', factor=0.5, patience=1, cooldown=1,\n",
    "    threshold=1e-4, threshold_mode='abs', min_lr=LR_MIN\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_AMP = (DEVICE.type == \"cuda\")\n",
    "BF16_OK = (USE_AMP and torch.cuda.is_bf16_supported())\n",
    "print(f\"[Device] {DEVICE}; AMP={USE_AMP}\")\n",
    "\n",
    "# â€”â€” æ•°å€¼åŠ é€Ÿï¼šTF32 / compile â€”â€”\n",
    "try:\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    cudnn.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if USE_AMP:\n",
    "    try:\n",
    "        # åœ¨ä½ çš„åŸé…ç½®ä¸Šä¿æŒ reduce-overheadï¼ˆå…¼å®¹æ€§æ›´å¥½ï¼‰\n",
    "        model = torch.compile(model, mode=\"reduce-overhead\")\n",
    "        print(\"âœ… torch.compile enabled (reduce-overhead)\")\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ torch.compile failed:\", e)\n",
    "\n",
    "# â€”â€” ä¸€é”®å¼€å…³ï¼šå¤šè¿›ç¨‹ DataLoaderï¼ˆNotebook ç¨³å¥è®¾ç½®ï¼‰ â€”â€”\n",
    "MULTIWORKER = True          # å¯æŒ‰éœ€å…³é—­\n",
    "FORCE_MULTIPROC = True      \n",
    "def _in_notebook(): return ('ipykernel' in sys.modules) or ('IPython' in sys.modules)\n",
    "IS_WINDOWS = (platform.system() == \"Windows\")\n",
    "\n",
    "# é»˜è®¤æ‰¹å¤§å°ï¼šGPU ç¨å¤§ã€CPU ä¿å®ˆ\n",
    "BATCH_SIZE = 512 if USE_AMP else 128\n",
    "\n",
    "if MULTIWORKER and (FORCE_MULTIPROC or (not _in_notebook())) and (not IS_WINDOWS):\n",
    "    # âœ… åœ¨ Linux/WSL ä¸Šä¼˜å…ˆä½¿ç”¨ forkï¼Œèƒ½è§„é¿ notebook + spawn çš„ pickling é—®é¢˜\n",
    "    try:\n",
    "        import multiprocessing as mp\n",
    "        mp.set_start_method(\"fork\", force=True)\n",
    "        start_method = \"fork\"\n",
    "    except Exception as e:\n",
    "        print(\"[DataLoader] set_start_method('fork') å¤±è´¥ï¼Œå›é€€ spawnï¼š\", e)\n",
    "        try:\n",
    "            import multiprocessing as mp\n",
    "            mp.set_start_method(\"spawn\", force=True)\n",
    "            start_method = \"spawn\"\n",
    "        except Exception as e2:\n",
    "            print(\"[DataLoader] set_start_method('spawn') ä¹Ÿå¤±è´¥ï¼Œé€€å›å•è¿›ç¨‹ï¼š\", e2)\n",
    "            NUM_WORKERS = 0\n",
    "            PIN_MEMORY  = USE_AMP\n",
    "            PERSISTENT  = False\n",
    "            PREFETCH    = None\n",
    "            start_method = \"none\"\n",
    "    # ä»…å½“æˆåŠŸè®¾ç½®äº†å¯åŠ¨æ–¹å¼æ‰é…ç½®å¤šè¿›ç¨‹å‚æ•°\n",
    "    if 'start_method' in locals() and start_method in (\"fork\", \"spawn\"):\n",
    "        NUM_WORKERS = 8          # ä¸ç”¨å¤ªå¤šï¼Œç¨³ä¸ºä¸»\n",
    "        PIN_MEMORY  = USE_AMP\n",
    "        PERSISTENT  = False      # Notebook ä¸‹å»ºè®®å…ˆå…³\n",
    "        PREFETCH    = 1\n",
    "        print(f\"[DataLoader] multiprocess ON: workers={NUM_WORKERS}, \"\n",
    "              f\"persistent={PERSISTENT}, prefetch={PREFETCH}, start_method={start_method}\")\n",
    "else:\n",
    "    # å•è¿›ç¨‹æ›´ç¨³ï¼ˆWindows / æ˜¾å¼å…³é—­ / Notebook æœªå¼ºåˆ¶ï¼‰\n",
    "    NUM_WORKERS = 0\n",
    "    PIN_MEMORY  = USE_AMP\n",
    "    PERSISTENT  = False\n",
    "    PREFETCH    = None\n",
    "    if MULTIWORKER and _in_notebook() and not FORCE_MULTIPROC:\n",
    "        print(\"[DataLoader] Notebook ç¯å¢ƒï¼šè‡ªåŠ¨é™çº§ workers=0ï¼ˆæ›´ç¨³ï¼‰\")\n",
    "    elif MULTIWORKER and IS_WINDOWS:\n",
    "        print(\"[DataLoader] Windows ç¯å¢ƒï¼šè‡ªåŠ¨é™çº§ workers=0\")\n",
    "\n",
    "def _build_loader(ds, shuffle):\n",
    "    return DataLoader(\n",
    "        ds, batch_size=BATCH_SIZE, shuffle=shuffle,\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
    "        persistent_workers=(PERSISTENT if NUM_WORKERS>0 else False),\n",
    "        prefetch_factor=(PREFETCH if (PREFETCH and NUM_WORKERS>0) else None)\n",
    "    )\n",
    "\n",
    "# ç›´æ¥å¤ç”¨ Step 1 äº§å‡ºçš„ train_dataset / valid_dataset\n",
    "train_loader = _build_loader(train_dataset, True)\n",
    "valid_loader = _build_loader(valid_dataset, False)\n",
    "\n",
    "# â€”â€” ä¼˜åŒ–å™¨/è°ƒåº¦å™¨/AMP â€”â€”\n",
    "def _group_adamw(m, lr, wd, fused):\n",
    "    emb_ids = set()\n",
    "    for mod in m.modules():\n",
    "        if isinstance(mod, nn.Embedding):\n",
    "            for p in mod.parameters(recurse=False):\n",
    "                emb_ids.add(id(p))\n",
    "    emb, other = [], []\n",
    "    for p in m.parameters():\n",
    "        if not p.requires_grad: continue\n",
    "        (emb if id(p) in emb_ids else other).append(p)\n",
    "    try:\n",
    "        opt = torch.optim.AdamW(\n",
    "            [{\"params\": emb, \"weight_decay\": 0.0},\n",
    "             {\"params\": other, \"weight_decay\": wd}],\n",
    "            lr=lr, fused=fused)\n",
    "    except TypeError:\n",
    "        opt = torch.optim.AdamW(\n",
    "            [{\"params\": emb, \"weight_decay\": 0.0},\n",
    "             {\"params\": other, \"weight_decay\": wd}],\n",
    "            lr=lr)\n",
    "    return opt\n",
    "\n",
    "optimizer = _group_adamw(model, LR, WEIGHT_DECAY, fused=USE_AMP)\n",
    "scheduler = ReduceLROnPlateau(optimizer, **SCHED_CFG) if USE_SCHED else None\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
    "\n",
    "# â€”â€” ç±»åˆ«ä¸å¹³è¡¡ä¼°è®¡ â€”â€”\n",
    "@torch.no_grad()\n",
    "def estimate_pos_weight(loader, sample_batches: int = 10):\n",
    "    pos = neg = checked = 0\n",
    "    for batch in loader:\n",
    "        y = batch[-1]\n",
    "        y = torch.nan_to_num(y, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "        pos += int((y > 0.5).sum().item())\n",
    "        neg += int((y <= 0.5).sum().item())\n",
    "        checked += 1\n",
    "        if checked >= sample_batches: break\n",
    "    pos = max(pos, 1); neg = max(neg, 1)\n",
    "    pw = neg / pos\n",
    "    print(f\"[ClassStats] pos={pos}, neg={neg}, pos_weightâ‰ˆ{pw:.2f}\")\n",
    "    return torch.tensor([pw], device=DEVICE, dtype=torch.float32)\n",
    "\n",
    "POS_WEIGHT   = estimate_pos_weight(train_loader, sample_batches=10)\n",
    "LABEL_SMOOTH = 0.05\n",
    "\n",
    "def _to_device(batch):\n",
    "    nb = (DEVICE.type == 'cuda')\n",
    "    return tuple(t.to(DEVICE, non_blocking=nb) for t in batch)\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    tot_loss = tot_samples = 0\n",
    "    skipped = 0\n",
    "    pbar = tqdm(train_loader, desc=\"Train\", dynamic_ncols=True, mininterval=0.3, leave=False)\n",
    "    for batch in pbar:\n",
    "        batch = _to_device(batch)\n",
    "        if batch[-1].numel() == 0:\n",
    "            skipped += 1; continue\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=DEVICE.type, enabled=USE_AMP,\n",
    "                                dtype=torch.bfloat16 if BF16_OK else torch.float16):\n",
    "            logits = torch.clamp(model(*batch[:-1]), -20, 20)\n",
    "            y = torch.nan_to_num(batch[-1], nan=0.0, posinf=1.0, neginf=0.0)\n",
    "            targets = y * (1.0 - LABEL_SMOOTH) + (1.0 - y) * LABEL_SMOOTH\n",
    "            per_sample = F.binary_cross_entropy_with_logits(\n",
    "                logits, targets, reduction='none', pos_weight=POS_WEIGHT)\n",
    "        mask = torch.isfinite(per_sample)\n",
    "        if not mask.any():\n",
    "            skipped += 1; continue\n",
    "        loss = per_sample[mask].mean()\n",
    "        scaler.scale(loss).backward()\n",
    "        if GRAD_CLIP_NORM and GRAD_CLIP_NORM > 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_NORM)\n",
    "        scaler.step(optimizer); scaler.update()\n",
    "        tot_loss   += loss.item() * int(mask.sum().item())\n",
    "        tot_samples += int(mask.sum().item())\n",
    "        pbar.set_postfix(loss=f\"{(tot_loss/max(1,tot_samples)):.5f}\")\n",
    "    pbar.close()\n",
    "    if skipped: print(f\"[WARN] train skipped {skipped} batches\")\n",
    "    return tot_loss / max(1, tot_samples)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    tot_loss = tot_samples = 0\n",
    "    skipped = 0\n",
    "    all_logits, all_labels = [], []\n",
    "    pbar = tqdm(valid_loader, desc=\"Valid\", dynamic_ncols=True, mininterval=0.5, leave=False)\n",
    "    with torch.amp.autocast(device_type=DEVICE.type, enabled=USE_AMP,\n",
    "                            dtype=torch.bfloat16 if BF16_OK else torch.float16):\n",
    "        for batch in pbar:\n",
    "            batch = _to_device(batch)\n",
    "            if batch[-1].numel() == 0:\n",
    "                skipped += 1; continue\n",
    "            logits = torch.clamp(model(*batch[:-1]), -20, 20)\n",
    "            y = torch.nan_to_num(batch[-1], nan=0.0, posinf=1.0, neginf=0.0)\n",
    "            targets = y * (1.0 - LABEL_SMOOTH) + (1.0 - y) * LABEL_SMOOTH\n",
    "            per_sample = F.binary_cross_entropy_with_logits(\n",
    "                logits, targets, reduction='none', pos_weight=POS_WEIGHT)\n",
    "            mask = torch.isfinite(per_sample)\n",
    "            if not mask.any():\n",
    "                skipped += 1; continue\n",
    "            loss = per_sample[mask].mean()\n",
    "            tot_loss += loss.item() * int(mask.sum().item())\n",
    "            tot_samples += int(mask.sum().item())\n",
    "            all_logits.append(logits[mask].detach().cpu().float().numpy())\n",
    "            all_labels.append(y[mask].detach().cpu().numpy())\n",
    "    pbar.close()\n",
    "    if skipped: print(f\"[WARN] valid skipped {skipped} batches\")\n",
    "    if tot_samples == 0: return math.nan, math.nan, math.nan\n",
    "    logits = np.concatenate(all_logits); labels = np.concatenate(all_labels).astype(np.int64)\n",
    "    probs = np.clip(1.0/(1.0+np.exp(-logits)), 1e-7, 1-1e-7)\n",
    "    try: auc = roc_auc_score(labels, probs)\n",
    "    except Exception: auc = math.nan\n",
    "    try: ll = log_loss(labels, probs)\n",
    "    except Exception: ll = math.nan\n",
    "    return (tot_loss / tot_samples), auc, ll\n",
    "\n",
    "def _is_better(curr, best):\n",
    "    if best is None: return True\n",
    "    delta = curr - best if MODE == \"max\" else best - curr\n",
    "    return delta > MIN_DELTA\n",
    "\n",
    "history = {\"train_loss\": [], \"valid_loss\": [], \"valid_auc\": [], \"valid_logloss\": []}\n",
    "best_metric = None\n",
    "print(f\"å¼€å§‹è®­ç»ƒï¼šEPOCHS={EPOCHS}, BATCH_SIZE={BATCH_SIZE}, workers={NUM_WORKERS}, pin={PIN_MEMORY}, persistent={(PERSISTENT if NUM_WORKERS>0 else False)}\")\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "    tr = train_one_epoch()\n",
    "    vl, va, ll = evaluate()\n",
    "    history[\"train_loss\"].append(tr)\n",
    "    history[\"valid_loss\"].append(vl)\n",
    "    history[\"valid_auc\"].append(va)\n",
    "    history[\"valid_logloss\"].append(ll)\n",
    "    mon = va if MONITOR==\"auc\" else (-ll)\n",
    "    print(f\"[Epoch {epoch:02d}] TrainLoss={tr:.5f} | ValidLoss={vl:.5f} | AUC={va:.5f} | LogLoss={ll:.5f}\")\n",
    "\n",
    "    if _is_better(mon, best_metric):\n",
    "        best_metric = mon\n",
    "        torch.save(model.state_dict(), BEST_PATH)\n",
    "        print(f\"ğŸŸ¢ New best ({MONITOR}): save -> {BEST_PATH}\")\n",
    "\n",
    "    if USE_SCHED and scheduler is not None:\n",
    "        scheduler.step(va if not math.isnan(va) else -1.0)\n",
    "        cur_lr = min(g['lr'] for g in optimizer.param_groups)\n",
    "        if cur_lr <= LR_MIN and not _is_better(mon, best_metric):\n",
    "            print(f\"â¹ LR å·²åˆ°ä¸‹é™({LR_MIN:.1e})ä¸”æŒ‡æ ‡æ— æå‡ï¼Œæå‰åœæ­¢ã€‚\")\n",
    "            break\n",
    "\n",
    "    if EARLY_STOP and epoch >= PATIENCE:\n",
    "        recent = history[\"valid_auc\"][-PATIENCE:] if MONITOR==\"auc\" else [-x for x in history[\"valid_logloss\"][-PATIENCE:]]\n",
    "        if len(recent)==PATIENCE and max(recent)-min(recent) < MIN_DELTA:\n",
    "            print(f\"â¹ Early stop triggered at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "if best_metric is None and not os.path.exists(BEST_PATH):\n",
    "    torch.save(model.state_dict(), BEST_PATH)\n",
    "print(f\"\\nâœ… è®­ç»ƒå®Œæˆï¼›æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨ {BEST_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30622f3e-87e6-478c-ad9f-4a1748ca46aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step3B] å¼€å§‹è¯„ä¼°ä¸ç»˜å›¾ï¼ˆä½¿ç”¨éªŒè¯é›†ï¼‰\n",
      "[Step3B] å·²åŠ è½½æœ€ä½³æƒé‡ï¼šxdeepfm_best.pt\n",
      "[Step3B] æ¨ç†å®Œæˆï¼š89884 æ ·æœ¬ï¼Œç”¨æ—¶ 11.74sï¼›batch=2048, workers=8\n",
      "[Step3B] æŒ‡æ ‡ï¼šAUC=0.8985 | AP=0.7229 | Logloss=0.50421 | KS=0.0000 | Brier=0.16220\n",
      "\n",
      "[ç ”ç©¶ç‰ˆ] åˆ†ç»„è¯„ä¼°åˆ†æï¼š\n",
      "  Warmç”¨æˆ· (n=89854): AUC=0.8985 | AP=0.7230 | Brier=0.16217\n",
      "  Coldç”¨æˆ· (n=30): AUC=0.7500 | AP=0.4710 | Brier=0.25415\n",
      "  Warmèµ„äº§ (n=89864): AUC=0.8985 | AP=0.7230 | Brier=0.16218\n",
      "  Coldèµ„äº§ (n=20): AUC=0.3056 | AP=0.1042 | Brier=0.24507\n",
      "  çƒ­é—¨èµ„äº§Top10% (n=9074): AUC=0.7740 | AP=0.8823 | Brier=0.20217\n",
      "  æ™®é€šèµ„äº§ (n=80790): AUC=0.8694 | AP=0.5700 | Brier=0.15769\n",
      "  è®­ç»ƒé›†è§è¿‡çš„(user,asset)å¯¹ (n=10641): AUC=N/A | AP=N/A\n",
      "  è®­ç»ƒé›†æœªè§çš„(user,asset)å¯¹ (n=79243): AUC=0.8980 | AP=0.7427\n",
      "\n",
      "[Step3B] âœ… å·²ä¿å­˜ï¼šxdeepfm_ROC.png\n",
      "[Step3B] âœ… å·²ä¿å­˜ï¼šxdeepfm_PR.png\n",
      "[Step3B] ç¼“å­˜ï¼švalid_y_true.npy / valid_y_score.npy\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 3B: éªŒè¯é›†å¿«é€Ÿè¯„ä¼° + ROC/PR ç»˜å›¾ + åˆ†ç»„åˆ†æ\n",
    "# ä¾èµ–ï¼šmodel, DEVICE, USE_AMP, BEST_PATH, valid_dataset, train_df\n",
    "# äº§ç‰©ï¼šxdeepfm_ROC.png / xdeepfm_PR.png / valid_y_true.npy / valid_y_score.npy\n",
    "# ç ”ç©¶ç‰ˆæ–°å¢ï¼šWarm/Coldç”¨æˆ·èµ„äº§åˆ†æã€çƒ­é—¨åº¦åˆ†ç»„è¯„ä¼°\n",
    "# ================================\n",
    "import os, time, platform, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    roc_auc_score, log_loss\n",
    ")\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "print(\"\\n[Step3B] å¼€å§‹è¯„ä¼°ä¸ç»˜å›¾ï¼ˆä½¿ç”¨éªŒè¯é›†ï¼‰\")\n",
    "\n",
    "# ---- åŠ è½½ best æƒé‡ï¼ˆè‹¥å­˜åœ¨ï¼‰----\n",
    "if os.path.exists(BEST_PATH):\n",
    "    state = torch.load(BEST_PATH, map_location=\"cpu\")\n",
    "    if isinstance(state, dict):\n",
    "        model.load_state_dict(state)\n",
    "        print(f\"[Step3B] å·²åŠ è½½æœ€ä½³æƒé‡ï¼š{BEST_PATH}\")\n",
    "    else:\n",
    "        print(f\"[Step3B] è¯»å– {BEST_PATH} ç»“æœé state_dictï¼Œè·³è¿‡åŠ è½½ã€‚\")\n",
    "else:\n",
    "    print(f\"[Step3B] æœªæ‰¾åˆ° {BEST_PATH}ï¼Œä½¿ç”¨å½“å‰å†…å­˜ä¸­çš„æ¨¡å‹å‚æ•°ã€‚\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# ---- Eval DataLoaderï¼ˆéªŒè¯é˜¶æ®µå¯ç”¨æ›´å¤§ batchï¼‰----\n",
    "IS_WINDOWS = (platform.system() == \"Windows\")\n",
    "CPU_COUNT = os.cpu_count() or 8\n",
    "EVAL_BATCH_SIZE = 2048 if USE_AMP else 512\n",
    "NUM_WORKERS = (max(2, CPU_COUNT//2) if not IS_WINDOWS else 0) if USE_AMP else 0\n",
    "PIN_MEMORY  = bool(USE_AMP)\n",
    "PERSISTENT  = bool(USE_AMP and NUM_WORKERS > 0)\n",
    "PREFETCH    = 2 if (USE_AMP and NUM_WORKERS > 0) else None\n",
    "\n",
    "def make_eval_loader(dataset):\n",
    "    kwargs = dict(\n",
    "        dataset=dataset,\n",
    "        batch_size=EVAL_BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        persistent_workers=PERSISTENT\n",
    "    )\n",
    "    if PREFETCH is not None:\n",
    "        kwargs[\"prefetch_factor\"] = PREFETCH\n",
    "    return DataLoader(**kwargs)\n",
    "\n",
    "valid_loader_eval = make_eval_loader(valid_dataset)\n",
    "\n",
    "# ---- å°å·¥å…·ï¼šæ›´å¥å£®çš„æŒ‡æ ‡è®¡ç®— ----\n",
    "def _class_counts(y):\n",
    "    y = np.asarray(y).astype(int)\n",
    "    pos = int(np.sum(y == 1))\n",
    "    neg = int(np.sum(y == 0))\n",
    "    return pos, neg\n",
    "\n",
    "def quick_metrics(y_true, y_score, ks_bins=100):\n",
    "    \"\"\"\n",
    "    å¥å£®æŒ‡æ ‡ï¼š\n",
    "    * åªæœ‰ä¸¤ç±»åŒæ—¶å­˜åœ¨æ—¶æ‰è®¡ç®— AUC/AP/KSï¼›\n",
    "    * log_loss æ˜¾å¼ labels=[0,1]ï¼Œè‹¥åªæœ‰ä¸€ç±»è¿”å› np.nanï¼›\n",
    "    * Brier æ€»èƒ½ç®—ã€‚\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_score = np.asarray(y_score).astype(float)\n",
    "    y_score = np.clip(y_score, 1e-7, 1-1e-7)\n",
    "\n",
    "    out = {}\n",
    "    pos, neg = _class_counts(y_true)\n",
    "    both = (pos > 0 and neg > 0)\n",
    "\n",
    "    if both:\n",
    "        out[\"auc\"] = float(roc_auc_score(y_true, y_score))\n",
    "        out[\"ap\"]  = float(average_precision_score(y_true, y_score))\n",
    "    else:\n",
    "        out[\"auc\"] = np.nan\n",
    "        out[\"ap\"]  = np.nan\n",
    "\n",
    "    try:\n",
    "        out[\"logloss\"] = float(log_loss(y_true, y_score, labels=[0, 1]))\n",
    "        if not both:\n",
    "            out[\"logloss\"] = np.nan\n",
    "    except Exception:\n",
    "        out[\"logloss\"] = np.nan\n",
    "\n",
    "    if both:\n",
    "        bins = np.linspace(0, 1, ks_bins+1)\n",
    "        idx = np.digitize(y_score, bins) - 1\n",
    "        tpr = np.zeros(ks_bins); fpr = np.zeros(ks_bins)\n",
    "        for b in range(ks_bins):\n",
    "            tpr[b] = (y_true[idx == b] == 1).sum()\n",
    "            fpr[b] = (y_true[idx == b] == 0).sum()\n",
    "        tpr = np.cumsum(tpr) / max(pos, 1)\n",
    "        fpr = np.cumsum(fpr) / max(neg, 1)\n",
    "        out[\"ks\"] = float(np.max(tpr - fpr))\n",
    "    else:\n",
    "        out[\"ks\"] = np.nan\n",
    "\n",
    "    out[\"brier\"] = float(np.mean((y_score - y_true)**2))\n",
    "    return out\n",
    "\n",
    "def fmt(x):\n",
    "    return \"N/A\" if (x is None or (isinstance(x, float) and (np.isnan(x) or np.isinf(x)))) else f\"{x:.4f}\"\n",
    "\n",
    "# ---- æ¨ç†ï¼ˆAMP + inference_mode + é¢„åˆ†é…ï¼‰----\n",
    "N = len(valid_dataset)\n",
    "if N == 0:\n",
    "    print(\"[Step3B] âš ï¸ éªŒè¯é›†ä¸ºç©ºï¼Œè·³è¿‡ã€‚\")\n",
    "else:\n",
    "    y_true = np.empty(N, dtype=np.int64)\n",
    "    y_score = np.empty(N, dtype=np.float32)\n",
    "    # ç ”ç©¶ç‰ˆæ–°å¢ï¼šä¿å­˜ user_idx / asset_idx ç”¨äºåˆ†ç»„åˆ†æ\n",
    "    all_user_idx = np.empty(N, dtype=np.int64)\n",
    "    all_asset_idx = np.empty(N, dtype=np.int64)\n",
    "    offset = 0\n",
    "\n",
    "    t0 = time.time()\n",
    "    with torch.inference_mode():\n",
    "        for batch in valid_loader_eval:\n",
    "            # æ•°æ®é›†è¿”å›ç»“æ„ï¼šuser_idx, user_cat, asset_idx, asset_cat, asset_num, label\n",
    "            user_idx, user_cat, asset_idx, asset_cat, asset_num, label = batch\n",
    "\n",
    "            bs = label.size(0)\n",
    "            # ä¿å­˜ç´¢å¼•åˆ° CPU æ•°ç»„ï¼ˆnumpyï¼‰\n",
    "            if user_idx.device.type != 'cpu':\n",
    "                all_user_idx[offset:offset+bs] = user_idx.cpu().numpy()\n",
    "            else:\n",
    "                all_user_idx[offset:offset+bs] = user_idx.numpy()\n",
    "\n",
    "            if asset_idx.device.type != 'cpu':\n",
    "                all_asset_idx[offset:offset+bs] = asset_idx.cpu().numpy()\n",
    "            else:\n",
    "                all_asset_idx[offset:offset+bs] = asset_idx.numpy()\n",
    "\n",
    "            # æ¬åˆ°è®¾å¤‡\n",
    "            nb = (DEVICE.type == \"cuda\")\n",
    "            user_idx  = user_idx.to(DEVICE, non_blocking=nb)\n",
    "            user_cat  = user_cat.to(DEVICE, non_blocking=nb)\n",
    "            asset_idx = asset_idx.to(DEVICE, non_blocking=nb)\n",
    "            asset_cat = asset_cat.to(DEVICE, non_blocking=nb)\n",
    "            asset_num = asset_num.to(DEVICE, non_blocking=nb)\n",
    "\n",
    "            with torch.amp.autocast(device_type=DEVICE.type, enabled=USE_AMP):\n",
    "                logits = model(user_idx, user_cat, asset_idx, asset_cat, asset_num)\n",
    "                probs  = torch.sigmoid(logits).float()\n",
    "\n",
    "            # label -> y_true\n",
    "            l_cpu = label.detach().cpu().numpy()\n",
    "            y_true[offset:offset+bs]  = l_cpu.astype(np.int64)\n",
    "            y_score[offset:offset+bs] = probs.detach().cpu().numpy().astype(np.float32)\n",
    "            offset += bs\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[Step3B] æ¨ç†å®Œæˆï¼š{N} æ ·æœ¬ï¼Œç”¨æ—¶ {dt:.2f}sï¼›batch={EVAL_BATCH_SIZE}, workers={NUM_WORKERS}\")\n",
    "\n",
    "    # ---- æŒ‡æ ‡ï¼ˆå…¨é‡ï¼‰----\n",
    "    y_score = np.clip(y_score, 1e-7, 1 - 1e-7)\n",
    "    metrics = quick_metrics(y_true, y_score)\n",
    "    print(f\"[Step3B] æŒ‡æ ‡ï¼šAUC={fmt(metrics['auc'])} | AP={fmt(metrics['ap'])} | \"\n",
    "          f\"Logloss={('N/A' if (metrics['logloss'] is None or np.isnan(metrics['logloss'])) else f'{metrics['logloss']:.5f}')} | \"\n",
    "          f\"KS={fmt(metrics['ks'])} | Brier={(metrics['brier']):.5f}\")\n",
    "\n",
    "    # ================================\n",
    "    # åˆ†ç»„è¯„ä¼°ï¼ˆè¯Šæ–­AUCè™šé«˜æ¥æºï¼‰\n",
    "    # ================================\n",
    "    print(\"\\n[ç ”ç©¶ç‰ˆ] åˆ†ç»„è¯„ä¼°åˆ†æï¼š\")\n",
    "\n",
    "    # 1) Warm/Cold ç”¨æˆ·ï¼ˆæ˜¯å¦åœ¨è®­ç»ƒå‡ºç°è¿‡ï¼‰\n",
    "    if 'train_df' in globals():\n",
    "        train_user_set = set(pd.Series(train_df['user_idx']).unique())\n",
    "        warm_user_mask = np.array([uid in train_user_set for uid in all_user_idx], dtype=bool)\n",
    "        cold_user_mask = ~warm_user_mask\n",
    "\n",
    "        if warm_user_mask.sum() > 0:\n",
    "            m = quick_metrics(y_true[warm_user_mask], y_score[warm_user_mask])\n",
    "            print(f\"  Warmç”¨æˆ· (n={warm_user_mask.sum()}): AUC={fmt(m['auc'])} | AP={fmt(m['ap'])} | Brier={(m['brier']):.5f}\")\n",
    "        else:\n",
    "            print(\"  Warmç”¨æˆ·ï¼šæ— æ ·æœ¬\")\n",
    "\n",
    "        if cold_user_mask.sum() > 0:\n",
    "            m = quick_metrics(y_true[cold_user_mask], y_score[cold_user_mask])\n",
    "            print(f\"  Coldç”¨æˆ· (n={cold_user_mask.sum()}): AUC={fmt(m['auc'])} | AP={fmt(m['ap'])} | Brier={(m['brier']):.5f}\")\n",
    "        else:\n",
    "            print(\"  Coldç”¨æˆ·ï¼šæ— æ ·æœ¬\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ ç¼ºå°‘ train_dfï¼Œè·³è¿‡ Warm/Cold ç”¨æˆ·åˆ†æã€‚\")\n",
    "\n",
    "    # 2) Warm/Cold èµ„äº§ï¼ˆæ˜¯å¦åœ¨è®­ç»ƒå‡ºç°è¿‡ï¼‰\n",
    "    if 'train_df' in globals():\n",
    "        train_asset_set = set(pd.Series(train_df['asset_idx']).unique())\n",
    "        warm_asset_mask = np.array([aid in train_asset_set for aid in all_asset_idx], dtype=bool)\n",
    "        cold_asset_mask = ~warm_asset_mask\n",
    "\n",
    "        if warm_asset_mask.sum() > 0:\n",
    "            m = quick_metrics(y_true[warm_asset_mask], y_score[warm_asset_mask])\n",
    "            print(f\"  Warmèµ„äº§ (n={warm_asset_mask.sum()}): AUC={fmt(m['auc'])} | AP={fmt(m['ap'])} | Brier={(m['brier']):.5f}\")\n",
    "        else:\n",
    "            print(\"  Warmèµ„äº§ï¼šæ— æ ·æœ¬\")\n",
    "\n",
    "        if cold_asset_mask.sum() > 0:\n",
    "            m = quick_metrics(y_true[cold_asset_mask], y_score[cold_asset_mask])\n",
    "            print(f\"  Coldèµ„äº§ (n={cold_asset_mask.sum()}): AUC={fmt(m['auc'])} | AP={fmt(m['ap'])} | Brier={(m['brier']):.5f}\")\n",
    "        else:\n",
    "            print(\"  Coldèµ„äº§ï¼šæ— æ ·æœ¬\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ ç¼ºå°‘ train_dfï¼Œè·³è¿‡ Warm/Cold èµ„äº§åˆ†æã€‚\")\n",
    "\n",
    "    # 3) çƒ­é—¨èµ„äº§ï¼ˆæŒ‰è®­ç»ƒé›†å‡ºç°æ¬¡æ•° Top10%ï¼‰\n",
    "    if 'train_df' in globals():\n",
    "        asset_popularity = pd.Series(train_df['asset_idx']).value_counts().to_dict()\n",
    "        asset_pop_values = np.array([asset_popularity.get(aid, 0) for aid in all_asset_idx])\n",
    "\n",
    "        if asset_pop_values.max() > 0:\n",
    "            pos_mask = (asset_pop_values > 0)\n",
    "            if pos_mask.any():\n",
    "                pop_q90 = np.percentile(asset_pop_values[pos_mask], 90)\n",
    "                hot_asset_mask = (asset_pop_values >= pop_q90)\n",
    "                normal_asset_mask = (asset_pop_values > 0) & (asset_pop_values < pop_q90)\n",
    "\n",
    "                if hot_asset_mask.sum() > 0:\n",
    "                    m = quick_metrics(y_true[hot_asset_mask], y_score[hot_asset_mask])\n",
    "                    print(f\"  çƒ­é—¨èµ„äº§Top10% (n={hot_asset_mask.sum()}): AUC={fmt(m['auc'])} | AP={fmt(m['ap'])} | Brier={(m['brier']):.5f}\")\n",
    "                else:\n",
    "                    print(\"  çƒ­é—¨èµ„äº§Top10%ï¼šæ— æ ·æœ¬\")\n",
    "\n",
    "                if normal_asset_mask.sum() > 0:\n",
    "                    m = quick_metrics(y_true[normal_asset_mask], y_score[normal_asset_mask])\n",
    "                    print(f\"  æ™®é€šèµ„äº§ (n={normal_asset_mask.sum()}): AUC={fmt(m['auc'])} | AP={fmt(m['ap'])} | Brier={(m['brier']):.5f}\")\n",
    "                else:\n",
    "                    print(\"  æ™®é€šèµ„äº§ï¼šæ— æ ·æœ¬\")\n",
    "            else:\n",
    "                print(\"  çƒ­é—¨èµ„äº§åˆ†æï¼šéªŒè¯é›†ä¸­èµ„äº§ä»æœªåœ¨è®­ç»ƒå‡ºç°ï¼Œè·³è¿‡ã€‚\")\n",
    "        else:\n",
    "            print(\"  çƒ­é—¨èµ„äº§åˆ†æï¼šéªŒè¯é›†ä¸­èµ„äº§çƒ­åº¦ä¸º 0ï¼Œè·³è¿‡ã€‚\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ ç¼ºå°‘ train_dfï¼Œè·³è¿‡çƒ­é—¨åº¦åˆ†ç»„ã€‚\")\n",
    "\n",
    "    # 4) å…±ç°åˆ†æï¼šè®­ç»ƒé›†è§è¿‡çš„ (user, asset) å¯¹\n",
    "    if 'train_df' in globals():\n",
    "        train_pairs = set(zip(train_df['user_idx'], train_df['asset_idx']))\n",
    "        seen_pair_mask = np.array([(uid, aid) in train_pairs for uid, aid in zip(all_user_idx, all_asset_idx)], dtype=bool)\n",
    "        unseen_pair_mask = ~seen_pair_mask\n",
    "\n",
    "        if seen_pair_mask.sum() > 0:\n",
    "            m = quick_metrics(y_true[seen_pair_mask], y_score[seen_pair_mask])\n",
    "            print(f\"  è®­ç»ƒé›†è§è¿‡çš„(user,asset)å¯¹ (n={seen_pair_mask.sum()}): AUC={fmt(m['auc'])} | AP={fmt(m['ap'])}\")\n",
    "        else:\n",
    "            print(\"  è®­ç»ƒé›†è§è¿‡çš„(user,asset)å¯¹ï¼šæ— æ ·æœ¬\")\n",
    "\n",
    "        if unseen_pair_mask.sum() > 0:\n",
    "            m = quick_metrics(y_true[unseen_pair_mask], y_score[unseen_pair_mask])\n",
    "            print(f\"  è®­ç»ƒé›†æœªè§çš„(user,asset)å¯¹ (n={unseen_pair_mask.sum()}): AUC={fmt(m['auc'])} | AP={fmt(m['ap'])}\")\n",
    "        else:\n",
    "            print(\"  è®­ç»ƒé›†æœªè§çš„(user,asset)å¯¹ï¼šæ— æ ·æœ¬\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ ç¼ºå°‘ train_dfï¼Œè·³è¿‡å…±ç°åˆ†æã€‚\")\n",
    "\n",
    "    # ---- ç»˜å›¾å¹¶ä¿å­˜ï¼ˆROC / PRï¼‰ï¼Œä»…åœ¨ä¸¤ç±»éƒ½å­˜åœ¨æ—¶ç»˜åˆ¶ ----\n",
    "    pos_all, neg_all = _class_counts(y_true)\n",
    "    both_all = (pos_all > 0 and neg_all > 0)\n",
    "\n",
    "    if both_all:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, lw=2, label=f\"ROC (AUC = {roc_auc:.4f})\")\n",
    "        plt.plot([0,1],[0,1],'--',lw=1.2)\n",
    "        plt.xlim([0,1]); plt.ylim([0,1.05])\n",
    "        plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"Receiver Operating Characteristic\")\n",
    "        plt.legend(loc=\"lower right\"); plt.grid(alpha=0.3)\n",
    "        plt.tight_layout(); plt.savefig(\"xdeepfm_ROC.png\", dpi=150); plt.close()\n",
    "        print(\"\\n[Step3B] âœ… å·²ä¿å­˜ï¼šxdeepfm_ROC.png\")\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "        ap = average_precision_score(y_true, y_score)\n",
    "        plt.figure()\n",
    "        plt.plot(recall, precision, lw=2, label=f\"PR (AP = {ap:.4f})\")\n",
    "        plt.xlim([0,1]); plt.ylim([0,1.05])\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "        plt.title(\"Precisionâ€“Recall Curve\")\n",
    "        plt.legend(loc=\"lower left\"); plt.grid(alpha=0.3)\n",
    "        plt.tight_layout(); plt.savefig(\"xdeepfm_PR.png\", dpi=150); plt.close()\n",
    "        print(\"[Step3B] âœ… å·²ä¿å­˜ï¼šxdeepfm_PR.png\")\n",
    "    else:\n",
    "        print(\"\\n[Step3B] âš ï¸ éªŒè¯é›†åªæœ‰å•ä¸€ç±»åˆ«ï¼Œè·³è¿‡ ROC/PR æ›²çº¿ã€‚\")\n",
    "\n",
    "    # ---- ä¿å­˜ä¸­é—´ç»“æœï¼Œåç»­ç”»å›¾æ— éœ€å†æ¨ç† ----\n",
    "    np.save(\"valid_y_true.npy\",  y_true)\n",
    "    np.save(\"valid_y_score.npy\", y_score)\n",
    "    print(\"[Step3B] ç¼“å­˜ï¼švalid_y_true.npy / valid_y_score.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facaeec1-9de2-4aaa-8cf9-cf860d0a18a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step3C] å¼€å§‹æŒ‰ç”¨æˆ·çš„æ’åºæŒ‡æ ‡è¯„ä¼°ï¼ˆåŸºäºéªŒè¯é›†ä¸­å·²æœ‰å€™é€‰ï¼‰...\n",
      "[Step3C] Overall AUC = 0.8985\n",
      "[Step3C] Users with >=1 positive in valid = 10968\n",
      "[Step3C] Hit@5 = 0.9956\n",
      "[Step3C] Hit@10 = 0.9995\n",
      "[Step3C] MRR = 0.9219\n",
      "[Step3C] NDCG@5 = 0.9196\n",
      "[Step3C] NDCG@10 = 0.9289\n",
      "[Step3C] å®Œæˆï¼ˆä»…ä½œç ”ç©¶è§‚å¯Ÿï¼Œä¸å½±å“è®­ç»ƒ/å¯¼å‡ºï¼‰ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 3Cï¼šæŒ‰ç”¨æˆ·çš„æ’åºæŒ‡æ ‡ï¼ˆHit@K / MRR / NDCG@Kï¼‰\n",
    "# ä¾èµ–ï¼šmodel, DEVICE, USE_AMP, valid_dataset\n",
    "# ================================\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "K_LIST = [5, 10]  # å¯æ”¹ä¸º [5, 10, 20]\n",
    "\n",
    "def make_eval_loader_for_userwise(dataset):\n",
    "    num_workers = 4 if USE_AMP else 0\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=(2048 if USE_AMP else 512),\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True if USE_AMP else False,\n",
    "        persistent_workers=True if (USE_AMP and num_workers>0) else False,\n",
    "        prefetch_factor=(2 if (USE_AMP and num_workers>0) else None),\n",
    "    )\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_valid_arrays():\n",
    "    loader = make_eval_loader_for_userwise(valid_dataset)\n",
    "    model.eval().to(DEVICE)\n",
    "    users, items, labels, scores = [], [], [], []\n",
    "    with torch.inference_mode():\n",
    "        for batch in loader:\n",
    "            u, ucat, a, acat, anum, y = batch\n",
    "            u_d = u.to(DEVICE, non_blocking=USE_AMP)\n",
    "            ucat_d = ucat.to(DEVICE, non_blocking=USE_AMP)\n",
    "            a_d = a.to(DEVICE, non_blocking=USE_AMP)\n",
    "            acat_d = acat.to(DEVICE, non_blocking=USE_AMP)\n",
    "            anum_d = anum.to(DEVICE, non_blocking=USE_AMP)\n",
    "            with torch.amp.autocast(device_type=DEVICE.type, enabled=USE_AMP):\n",
    "                logit = model(u_d, ucat_d, a_d, acat_d, anum_d)\n",
    "                prob = torch.sigmoid(logit).float().detach().cpu().numpy()\n",
    "            users.append(u.cpu().numpy()); items.append(a.cpu().numpy())\n",
    "            labels.append(y.cpu().numpy()); scores.append(prob)\n",
    "    users = np.concatenate(users)\n",
    "    items = np.concatenate(items)\n",
    "    labels = np.concatenate(labels).astype(np.int64)\n",
    "    scores = np.concatenate(scores).astype(np.float32)\n",
    "    return users, items, labels, scores\n",
    "\n",
    "def dcg_at_k(rel_sorted, k):\n",
    "    \"\"\"æ”¯æŒæ ·æœ¬æ•°å°‘äº k çš„æƒ…å†µ\"\"\"\n",
    "    if rel_sorted.size == 0:\n",
    "        return 0.0\n",
    "    eff_k = min(k, rel_sorted.size)\n",
    "    rel = rel_sorted[:eff_k]\n",
    "    denom = np.log2(np.arange(2, eff_k + 2))\n",
    "    return float(np.sum((2.0**rel - 1.0) / denom))\n",
    "\n",
    "def ndcg_at_k(rel_sorted, k):\n",
    "    \"\"\"æ”¯æŒæ ·æœ¬æ•°å°‘äº k çš„æƒ…å†µ\"\"\"\n",
    "    if rel_sorted.size == 0:\n",
    "        return 0.0\n",
    "    eff_k = min(k, rel_sorted.size)\n",
    "    ideal = np.sort(rel_sorted)[::-1][:eff_k]\n",
    "    return dcg_at_k(rel_sorted, eff_k) / max(dcg_at_k(ideal, eff_k), 1e-9)\n",
    "\n",
    "def compute_userwise_metrics(users, items, labels, scores, K_list=(5,10)):\n",
    "    # æŒ‰ç”¨æˆ·èšåˆå€™é€‰ï¼ˆä»…éªŒè¯é›†ä¸­å·²æœ‰çš„æ ·æœ¬ï¼‰\n",
    "    by_user = defaultdict(list)\n",
    "    for u, it, y, s in zip(users, items, labels, scores):\n",
    "        by_user[int(u)].append((int(it), int(y), float(s)))\n",
    "\n",
    "    hits = {k: [] for k in K_list}\n",
    "    mrrs = []\n",
    "    ndcgs = {k: [] for k in K_list}\n",
    "\n",
    "    valid_users = 0\n",
    "    for u, lst in by_user.items():\n",
    "        # è¯¥ç”¨æˆ·åœ¨éªŒè¯é›†é‡Œå¦‚æœæ²¡æœ‰ä»»ä½•æ­£ä¾‹ï¼Œå°±è·³è¿‡\n",
    "        if not any(y==1 for _, y, _ in lst):\n",
    "            continue\n",
    "        valid_users += 1\n",
    "\n",
    "        # æŒ‰æ¦‚ç‡ä»é«˜åˆ°ä½æ’åº\n",
    "        lst_sorted = sorted(lst, key=lambda x: x[2], reverse=True)\n",
    "        rel = np.array([y for _, y, _ in lst_sorted], dtype=np.float32)\n",
    "\n",
    "        # Hit@Kï¼ˆè€ƒè™‘æ ·æœ¬æ•°å°‘äº kï¼‰\n",
    "        for k in K_list:\n",
    "            eff_k = min(k, rel.size)\n",
    "            hit = float(rel[:eff_k].max()) if eff_k > 0 else 0.0\n",
    "            hits[k].append(hit)\n",
    "\n",
    "        # MRRï¼šç¬¬ä¸€ä¸ªæ­£ä¾‹çš„å€’æ•°æ’å\n",
    "        rr = 0.0\n",
    "        for rank, y in enumerate(rel, start=1):\n",
    "            if y > 0.5:\n",
    "                rr = 1.0 / rank\n",
    "                break\n",
    "        mrrs.append(rr)\n",
    "\n",
    "        # NDCG@Kï¼ˆå†…éƒ¨å·²å¤„ç† eff_kï¼‰\n",
    "        for k in K_list:\n",
    "            ndcgs[k].append(ndcg_at_k(rel, k))\n",
    "\n",
    "    out = {\n",
    "        \"num_users_with_positive\": valid_users,\n",
    "        \"Hit@K\": {k: float(np.mean(hits[k])) if hits[k] else float(\"nan\") for k in K_list},\n",
    "        \"MRR\": float(np.mean(mrrs)) if mrrs else float(\"nan\"),\n",
    "        \"NDCG@K\": {k: float(np.mean(ndcgs[k])) if ndcgs[k] else float(\"nan\") for k in K_list},\n",
    "    }\n",
    "    return out\n",
    "\n",
    "# â€”â€” æ‰§è¡Œ â€”â€” #\n",
    "print(\"\\n[Step3C] å¼€å§‹æŒ‰ç”¨æˆ·çš„æ’åºæŒ‡æ ‡è¯„ä¼°ï¼ˆåŸºäºéªŒè¯é›†ä¸­å·²æœ‰å€™é€‰ï¼‰...\")\n",
    "u_all, i_all, y_all, s_all = collect_valid_arrays()\n",
    "auc_overall = roc_auc_score(y_all, s_all) if (y_all.sum()>0 and (1-y_all).sum()>0) else float(\"nan\")\n",
    "userwise = compute_userwise_metrics(u_all, i_all, y_all, s_all, K_list=K_LIST)\n",
    "\n",
    "print(f\"[Step3C] Overall AUC = {auc_overall:.4f}\")\n",
    "print(f\"[Step3C] Users with >=1 positive in valid = {userwise['num_users_with_positive']}\")\n",
    "for k, v in userwise[\"Hit@K\"].items():\n",
    "    print(f\"[Step3C] Hit@{k} = {v:.4f}\")\n",
    "print(f\"[Step3C] MRR = {userwise['MRR']:.4f}\")\n",
    "for k, v in userwise[\"NDCG@K\"].items():\n",
    "    print(f\"[Step3C] NDCG@{k} = {v:.4f}\")\n",
    "print(\"[Step3C] å®Œæˆï¼ˆä»…ä½œç ”ç©¶è§‚å¯Ÿï¼Œä¸å½±å“è®­ç»ƒ/å¯¼å‡ºï¼‰ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2047a5f8-582c-4e40-833f-aedab897fc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ç ”ç©¶ç‰ˆ] è¿‡æ‹Ÿåˆåˆ†æï¼š\n",
      "  æœ€ç»ˆLosså·®è·: 0.19520\n",
      "  è¯Šæ–­: ä¸¥é‡è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ æ­£åˆ™åŒ–\n",
      "\n",
      "[ç ”ç©¶ç‰ˆ] è®­ç»ƒæ‘˜è¦ï¼š\n",
      "  æœ€ä½³AUC: 0.89848 @ Epoch 2\n",
      "  æœ€ç»ˆAUC: 0.87761\n",
      "  æç¤º: æœ€ç»ˆæ¨¡å‹ä¸æ˜¯æœ€ä¼˜ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ\n",
      "  æœ€ä½³LogLoss: 0.47145 @ Epoch 4\n",
      "  æœ€ç»ˆLogLoss: 0.48343\n",
      "\n",
      "è®­ç»ƒæ›²çº¿å·²ä¿å­˜ï¼š xdeepfm_training_loss.png / xdeepfm_training_auc.png / xdeepfm_training_logloss.png / xdeepfm_training_overfitting.png / xdeepfm_training_combined.png\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 4A: è®­ç»ƒæ›²çº¿å¯è§†åŒ–ï¼ˆLoss / AUC / Loglossï¼‰ã€ç ”ç©¶ç‰ˆã€‘\n",
    "# ä¾èµ–: history = {\"train_loss\": [], \"valid_loss\": [], \"valid_auc\": [], \"valid_logloss\": []}\n",
    "# å­¦ä¹ ç‡æ›²çº¿ã€è¿‡æ‹Ÿåˆç¨‹åº¦åˆ†æ\n",
    "# ================================\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def _clean_series(y: List[float]) -> np.ndarray:\n",
    "    \"\"\"æŠŠåˆ—è¡¨è½¬æˆ ndarrayï¼Œå¹¶å»æ‰å¤´å°¾çš„ NaNï¼ˆä¸­é—´ NaN ä¿ç•™ï¼Œé¿å…é”™ä½ï¼‰\"\"\"\n",
    "    if y is None:\n",
    "        return np.array([])\n",
    "    arr = np.asarray(y, dtype=float)\n",
    "    if arr.size == 0:\n",
    "        return arr\n",
    "    if np.isnan(arr).all():\n",
    "        return np.array([])\n",
    "    # å»æ‰å‰å NaNï¼Œä¿ç•™ä¸­é—´ NaN\n",
    "    first = np.argmax(~np.isnan(arr))\n",
    "    last = len(arr) - np.argmax(~np.isnan(arr[::-1]))\n",
    "    return arr[first:last]\n",
    "\n",
    "def _plot_xy(x: np.ndarray, ys: List[Tuple[np.ndarray, str]], title: str, ylabel: str,\n",
    "             save_path: Path, ylim: Tuple[float, float] = None):\n",
    "    \"\"\"é€šç”¨ç”»å›¾ï¼šæ”¯æŒå•ç‚¹ï¼Œç”¨ markerï¼Œè‡ªåŠ¨ç½‘æ ¼ä¸ç´§å‡‘å¸ƒå±€\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    drew = False\n",
    "    for y, label in ys:\n",
    "        if y.size == 0:\n",
    "            continue\n",
    "        n = min(x.size, y.size)\n",
    "        if n == 0:\n",
    "            continue\n",
    "        xx, yy = x[:n], y[:n]\n",
    "        plt.plot(xx, yy, label=label, marker='o', linewidth=1.5, markersize=4)\n",
    "        drew = True\n",
    "\n",
    "    if not drew:\n",
    "        plt.close()\n",
    "        return False\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(save_path), dpi=150)\n",
    "    plt.close()\n",
    "    return True\n",
    "\n",
    "def plot_training_curves(history: dict, save_prefix=\"xdeepfm_training\", save_dir: str = \".\"):\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # å–å‡ºå¹¶æ¸…æ´—\n",
    "    tl  = _clean_series(history.get(\"train_loss\"))\n",
    "    vl  = _clean_series(history.get(\"valid_loss\"))\n",
    "    va  = _clean_series(history.get(\"valid_auc\"))\n",
    "    vll = _clean_series(history.get(\"valid_logloss\"))\n",
    "\n",
    "    # ç»Ÿä¸€ x è½´ï¼ˆä»¥æœ€é•¿çš„ä¸€ä¸ªä¸ºå‡†ï¼‰\n",
    "    max_len = max([arr.size for arr in [tl, vl, va, vll]] + [0])\n",
    "    if max_len == 0:\n",
    "        print(\"âš ï¸ history ä¸ºç©ºæˆ–å…¨ NaNï¼Œæœªç”Ÿæˆä»»ä½•æ›²çº¿ã€‚\")\n",
    "        return\n",
    "\n",
    "    epochs = np.arange(1, max_len + 1)\n",
    "    saved = []\n",
    "\n",
    "    # 1) Lossæ›²çº¿\n",
    "    out_loss = save_dir / f\"{save_prefix}_loss.png\"\n",
    "    if _plot_xy(epochs,\n",
    "                [(tl, \"Train Loss\"), (vl, \"Valid Loss\")],\n",
    "                title=\"Training vs Validation Loss\",\n",
    "                ylabel=\"Loss\",\n",
    "                save_path=out_loss):\n",
    "        saved.append(out_loss.name)\n",
    "\n",
    "    # 2) AUCæ›²çº¿\n",
    "    out_auc = save_dir / f\"{save_prefix}_auc.png\"\n",
    "    if _plot_xy(epochs,\n",
    "                [(va, \"Valid AUC\")],\n",
    "                title=\"Validation AUC\",\n",
    "                ylabel=\"AUC\",\n",
    "                save_path=out_auc,\n",
    "                ylim=(0.0, 1.0)):\n",
    "        saved.append(out_auc.name)\n",
    "\n",
    "    # 3) Loglossæ›²çº¿\n",
    "    out_logloss = save_dir / f\"{save_prefix}_logloss.png\"\n",
    "    if vll.size > 0 and _plot_xy(epochs,\n",
    "                                 [(vll, \"Valid Logloss\")],\n",
    "                                 title=\"Validation Logloss\",\n",
    "                                 ylabel=\"Logloss\",\n",
    "                                 save_path=out_logloss):\n",
    "        saved.append(out_logloss.name)\n",
    "\n",
    "    # ================================\n",
    "    # è¯Šæ–­æ€§å¯è§†åŒ–\n",
    "    # ================================\n",
    "    \n",
    "    # 4) è¿‡æ‹Ÿåˆç¨‹åº¦åˆ†æï¼ˆTrain vs Valid Losså·®å¼‚ï¼‰\n",
    "    if tl.size > 0 and vl.size > 0:\n",
    "        n = min(tl.size, vl.size)\n",
    "        overfitting_gap = vl[:n] - tl[:n]\n",
    "        \n",
    "        out_overfit = save_dir / f\"{save_prefix}_overfitting.png\"\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(epochs[:n], overfitting_gap, 'r-o', label='Valid Loss - Train Loss', \n",
    "                linewidth=1.5, markersize=4)\n",
    "        plt.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss Gap\")\n",
    "        plt.title(\"Overfitting Analysis (Gap = Valid - Train)\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(out_overfit), dpi=150)\n",
    "        plt.close()\n",
    "        saved.append(out_overfit.name)\n",
    "        \n",
    "        # æ‰“å°è¿‡æ‹Ÿåˆè¯Šæ–­\n",
    "        final_gap = overfitting_gap[-1] if n > 0 else 0\n",
    "        print(f\"\\n[ç ”ç©¶ç‰ˆ] è¿‡æ‹Ÿåˆåˆ†æï¼š\")\n",
    "        print(f\"  æœ€ç»ˆLosså·®è·: {final_gap:.5f}\")\n",
    "        if final_gap < 0.01:\n",
    "            print(\"  è¯Šæ–­: åŸºæœ¬æ— è¿‡æ‹Ÿåˆ\")\n",
    "        elif final_gap < 0.05:\n",
    "            print(\"  è¯Šæ–­: è½»åº¦è¿‡æ‹Ÿåˆ\")\n",
    "        elif final_gap < 0.1:\n",
    "            print(\"  è¯Šæ–­: ä¸­åº¦è¿‡æ‹Ÿåˆ\")\n",
    "        else:\n",
    "            print(\"  è¯Šæ–­: ä¸¥é‡è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ æ­£åˆ™åŒ–\")\n",
    "    \n",
    "    # 5) ç»„åˆè¯Šæ–­å›¾ï¼ˆ2x2å­å›¾ï¼‰\n",
    "    if any([tl.size > 0, vl.size > 0, va.size > 0, vll.size > 0]):\n",
    "        out_combined = save_dir / f\"{save_prefix}_combined.png\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        fig.suptitle('Training Progress Overview', fontsize=16)\n",
    "        \n",
    "        # å­å›¾1: Loss\n",
    "        ax1 = axes[0, 0]\n",
    "        if tl.size > 0:\n",
    "            ax1.plot(epochs[:tl.size], tl, 'b-o', label='Train Loss', markersize=4)\n",
    "        if vl.size > 0:\n",
    "            ax1.plot(epochs[:vl.size], vl, 'r-o', label='Valid Loss', markersize=4)\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title('Loss Curves')\n",
    "        ax1.grid(alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # å­å›¾2: AUC\n",
    "        ax2 = axes[0, 1]\n",
    "        if va.size > 0:\n",
    "            ax2.plot(epochs[:va.size], va, 'g-o', label='Valid AUC', markersize=4)\n",
    "            ax2.set_ylim(0.0, 1.0)\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('AUC')\n",
    "        ax2.set_title('Validation AUC')\n",
    "        ax2.grid(alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        # å­å›¾3: LogLoss\n",
    "        ax3 = axes[1, 0]\n",
    "        if vll.size > 0:\n",
    "            ax3.plot(epochs[:vll.size], vll, 'm-o', label='Valid LogLoss', markersize=4)\n",
    "        ax3.set_xlabel('Epoch')\n",
    "        ax3.set_ylabel('LogLoss')\n",
    "        ax3.set_title('Validation LogLoss')\n",
    "        ax3.grid(alpha=0.3)\n",
    "        ax3.legend()\n",
    "        \n",
    "        # å­å›¾4: æ—©åœæŒ‡æ ‡ï¼ˆå‡è®¾ç”¨AUCï¼‰\n",
    "        ax4 = axes[1, 1]\n",
    "        if va.size > 0:\n",
    "            # æ ‡è®°æœ€ä½³epoch\n",
    "            best_epoch = np.argmax(va) + 1\n",
    "            ax4.plot(epochs[:va.size], va, 'b-o', markersize=4)\n",
    "            ax4.plot(best_epoch, va[best_epoch-1], 'r*', markersize=15, \n",
    "                    label=f'Best @ Epoch {best_epoch}')\n",
    "            ax4.set_ylim(0.0, 1.0)\n",
    "        ax4.set_xlabel('Epoch')\n",
    "        ax4.set_ylabel('Metric')\n",
    "        ax4.set_title('Early Stopping Monitor (AUC)')\n",
    "        ax4.grid(alpha=0.3)\n",
    "        ax4.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(str(out_combined), dpi=150)\n",
    "        plt.close()\n",
    "        saved.append(out_combined.name)\n",
    "    \n",
    "    # æ‰“å°è®­ç»ƒæ‘˜è¦\n",
    "    print(f\"\\n[ç ”ç©¶ç‰ˆ] è®­ç»ƒæ‘˜è¦ï¼š\")\n",
    "    if va.size > 0:\n",
    "        best_auc_epoch = np.argmax(va) + 1\n",
    "        print(f\"  æœ€ä½³AUC: {va[best_auc_epoch-1]:.5f} @ Epoch {best_auc_epoch}\")\n",
    "        print(f\"  æœ€ç»ˆAUC: {va[-1]:.5f}\")\n",
    "        if va[-1] < va[best_auc_epoch-1] - 0.001:\n",
    "            print(\"  æç¤º: æœ€ç»ˆæ¨¡å‹ä¸æ˜¯æœ€ä¼˜ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ\")\n",
    "    \n",
    "    if vll.size > 0:\n",
    "        best_ll_epoch = np.argmin(vll) + 1\n",
    "        print(f\"  æœ€ä½³LogLoss: {vll[best_ll_epoch-1]:.5f} @ Epoch {best_ll_epoch}\")\n",
    "        print(f\"  æœ€ç»ˆLogLoss: {vll[-1]:.5f}\")\n",
    "\n",
    "    if saved:\n",
    "        print(f\"\\nè®­ç»ƒæ›²çº¿å·²ä¿å­˜ï¼š {' / '.join(saved)}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æŒ‡æ ‡ä¸å¯ç”¨ï¼Œæœªç”Ÿæˆä»»ä½•æ›²çº¿ã€‚\")\n",
    "\n",
    "# è°ƒç”¨\n",
    "plot_training_curves(history, save_prefix=\"xdeepfm_training\", save_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08276f15-315f-4846-8ae4-38b170d600af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step4B] Device=cuda; AMP=True; BF16_OK=True\n",
      "[Step4B] é‡æ–°å®ä¾‹åŒ– XDeepFM...\n",
      "[Step4B] æ–° model ç±»å‹: <class '__main__.XDeepFM'>\n",
      "âœ… torch.compile enabled (Step4B)\n",
      "[Step4B] æˆåŠŸåŠ è½½æƒé‡ 'xdeepfm_best.pt'ã€‚\n",
      "[Step4B] æ„å»ºå…¨é‡è®­ç»ƒé›†...\n",
      "[Step4B ClassStats] pos=2031, neg=8209, pos_weightâ‰ˆ4.04\n",
      "\n",
      "[Step4B] å…¨é‡å¾®è°ƒï¼Œè®­ç»ƒ 1 è½®...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUTOTUNE addmm(1024x16, 1024x1, 1x16)9 [00:00<?, ?it/s]\n",
      "strides: [0, 1], [1, 1], [0, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16\n",
      "  triton_mm_1 0.0034 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2\n",
      "  triton_mm_4 0.0034 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_2 0.0035 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2\n",
      "  triton_mm_9 0.0035 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8\n",
      "  triton_mm_3 0.0035 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_6 0.0035 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4\n",
      "  triton_mm_7 0.0035 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_10 0.0035 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_5 0.0036 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_0 0.0036 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.2758 seconds and 0.0004 seconds precompiling for 13 choices\n",
      "E1116 07:04:33.456000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:33.456000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4. \n",
      "E1116 07:04:33.456000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "AUTOTUNE convolution(1024x400x16, 16x400x1)\n",
      "strides: [6400, 16, 1], [400, 1, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  convolution 0.0184 ms 100.0% \n",
      "  conv1x1_via_mm inf ms 0.0% \n",
      "SingleProcess AUTOTUNE benchmarking takes 0.1250 seconds and 0.0001 seconds precompiling for 2 choices\n",
      "E1116 07:04:33.481000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:33.481000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4. \n",
      "E1116 07:04:33.481000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "AUTOTUNE convolution(1024x320x16, 16x320x1)\n",
      "strides: [5120, 16, 1], [320, 1, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  convolution 0.0143 ms 100.0% \n",
      "  conv1x1_via_mm inf ms 0.0% \n",
      "SingleProcess AUTOTUNE benchmarking takes 0.0235 seconds and 0.0002 seconds precompiling for 2 choices\n",
      "E1116 07:04:33.690000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:33.690000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 131072 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:04:33.690000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "E1116 07:04:33.752000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:33.752000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 147456 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:04:33.752000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "E1116 07:04:33.854000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:33.854000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 131072 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:04:33.854000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "AUTOTUNE addmm(1024x128, 1024x320, 320x128)\n",
      "strides: [0, 1], [320, 1], [1, 320]\n",
      "dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16\n",
      "  triton_mm_78 0.0061 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_80 0.0061 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_81 0.0061 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_79 0.0061 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_84 0.0075 ms 81.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8\n",
      "  bias_addmm 0.0076 ms 80.3% \n",
      "  triton_mm_86 0.0082 ms 74.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_88 0.0082 ms 74.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_87 0.0082 ms 74.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_91 0.0082 ms 74.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.3716 seconds and 0.0003 seconds precompiling for 21 choices\n",
      "AUTOTUNE addmm(1024x64, 1024x128, 128x64)\n",
      "strides: [0, 1], [128, 1], [1, 128]\n",
      "dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16\n",
      "  bias_addmm 0.0041 ms 100.0% \n",
      "  triton_mm_97 0.0041 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_99 0.0041 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_100 0.0041 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_107 0.0054 ms 74.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_105 0.0055 ms 74.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_104 0.0055 ms 73.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_108 0.0055 ms 73.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4\n",
      "  triton_mm_98 0.0056 ms 73.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_103 0.0056 ms 73.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.3640 seconds and 0.0003 seconds precompiling for 20 choices\n",
      "E1116 07:04:40.205000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:40.205000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 131072 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:04:40.205000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "E1116 07:04:40.271000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:40.271000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 147456 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:04:40.271000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "E1116 07:04:40.380000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:40.380000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 131072 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:04:40.380000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "AUTOTUNE mm(128x1024, 1024x320)\n",
      "strides: [1, 128], [320, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  triton_mm_189 0.0082 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_187 0.0097 ms 84.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_188 0.0101 ms 80.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_186 0.0117 ms 69.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_192 0.0118 ms 69.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8\n",
      "  mm 0.0138 ms 59.3% \n",
      "  triton_mm_196 0.0164 ms 50.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_195 0.0178 ms 46.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_199 0.0179 ms 45.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_194 0.0179 ms 45.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.3592 seconds and 0.3130 seconds precompiling for 20 choices\n",
      "E1116 07:04:41.140000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:41.140000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 131072 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:04:41.140000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "E1116 07:04:41.206000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:41.206000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 147456 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:04:41.206000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "AUTOTUNE mm(64x1024, 1024x128)\n",
      "strides: [1, 64], [128, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  mm 0.0077 ms 100.0% \n",
      "  triton_mm_153 0.0082 ms 94.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_151 0.0096 ms 80.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_152 0.0097 ms 79.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_150 0.0102 ms 75.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_156 0.0116 ms 66.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8\n",
      "  triton_mm_163 0.0118 ms 65.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_162 0.0138 ms 55.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_159 0.0164 ms 47.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_160 0.0164 ms 47.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.3625 seconds and 0.0003 seconds precompiling for 18 choices\n",
      "AUTOTUNE mm(1024x1, 1x96)\n",
      "strides: [1, 1], [96, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  triton_mm_115 0.0034 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_119 0.0034 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_124 0.0035 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4\n",
      "  triton_mm_117 0.0035 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_120 0.0035 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8\n",
      "  triton_mm_122 0.0035 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_118 0.0035 ms 97.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  mm 0.0036 ms 96.4% \n",
      "  triton_mm_116 0.0036 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_114 0.0036 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.3121 seconds and 0.0002 seconds precompiling for 17 choices\n",
      "AUTOTUNE mm(1024x64, 64x128)\n",
      "strides: [64, 1], [128, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  triton_mm_131 0.0035 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_133 0.0036 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_134 0.0038 ms 91.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_136 0.0041 ms 85.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_137 0.0041 ms 85.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8\n",
      "  mm 0.0041 ms 84.4% \n",
      "  triton_mm_132 0.0041 ms 84.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_138 0.0041 ms 84.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_144 0.0052 ms 67.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_143 0.0055 ms 63.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.3610 seconds and 0.0003 seconds precompiling for 20 choices\n",
      "E1116 07:04:43.448000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Runtime error during autotuning: \n",
      "E1116 07:04:43.448000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 131072 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:04:43.448000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/2] Ignoring this choice.\n",
      "AUTOTUNE mm(1024x128, 128x320)\n",
      "strides: [128, 1], [320, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  triton_mm_168 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_167 0.0054 ms 75.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_170 0.0054 ms 75.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_173 0.0055 ms 74.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8\n",
      "  triton_mm_174 0.0055 ms 74.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_169 0.0055 ms 74.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8\n",
      "  triton_mm_175 0.0055 ms 74.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_179 0.0056 ms 73.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_180 0.0057 ms 71.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_176 0.0060 ms 68.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.3517 seconds and 0.0003 seconds precompiling for 20 choices\n",
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step4B] Epoch 1/1 Loss 0.84891\n",
      "[Step4B] å¾®è°ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³ xdeepfm_fulldata_final.pt\n",
      "[Step4B] å®½çŸ©é˜µè¡¨å¤´å†™å…¥ï¼Œå…± 807 åˆ—ï¼ˆå« customerIDï¼‰\n",
      "[Step4B] å¼€å§‹æ¨ç†å¯¼å‡ºå®½çŸ©é˜µ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUTOTUNE addmm(65536x16, 65536x1, 1x16)?it/s]\n",
      "strides: [0, 1], [1, 1], [0, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16\n",
      "  triton_mm_204 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2\n",
      "  triton_mm_205 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2\n",
      "  triton_mm_206 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2\n",
      "  triton_mm_207 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "  triton_mm_208 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_209 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_210 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4\n",
      "  triton_mm_211 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_212 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_213 0.0041 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.1977 seconds and 0.0003 seconds precompiling for 13 choices\n",
      "E1116 07:07:16.623000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] Runtime error during autotuning: \n",
      "E1116 07:07:16.623000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 131072 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:07:16.623000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] Ignoring this choice.\n",
      "E1116 07:07:16.695000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] Runtime error during autotuning: \n",
      "E1116 07:07:16.695000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 147456 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:07:16.695000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] Ignoring this choice.\n",
      "E1116 07:07:16.810000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] Runtime error during autotuning: \n",
      "E1116 07:07:16.810000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] No valid triton configs. OutOfMemoryError: out of resource: triton_mm Required: 131072 Hardware limit:101376 Reducing block sizes or `num_stages` may help.. \n",
      "E1116 07:07:16.810000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] Ignoring this choice.\n",
      "AUTOTUNE mm(65536x320, 320x128)\n",
      "strides: [320, 1], [1, 320]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  triton_mm_292 0.0425 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_288 0.0430 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8\n",
      "  triton_mm_290 0.0430 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_294 0.0430 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_291 0.0430 ms 98.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_295 0.0445 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_297 0.0446 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_287 0.0464 ms 91.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_298 0.0464 ms 91.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_296 0.0486 ms 87.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.4162 seconds and 0.0793 seconds precompiling for 20 choices\n",
      "AUTOTUNE mm(65536x128, 128x64)\n",
      "strides: [128, 1], [1, 128]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  triton_mm_313 0.0164 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_316 0.0179 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_306 0.0179 ms 91.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4\n",
      "  triton_mm_309 0.0179 ms 91.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_307 0.0179 ms 91.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8\n",
      "  triton_mm_311 0.0179 ms 91.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4\n",
      "  triton_mm_312 0.0184 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4\n",
      "  triton_mm_315 0.0184 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8\n",
      "  triton_mm_310 0.0192 ms 85.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8\n",
      "  triton_mm_304 0.0198 ms 82.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 0.3693 seconds and 0.0003 seconds precompiling for 19 choices\n",
      "E1116 07:07:17.263000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] Runtime error during autotuning: \n",
      "E1116 07:07:17.263000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4. \n",
      "E1116 07:07:17.263000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] Ignoring this choice.\n",
      "AUTOTUNE convolution(65536x400x16, 16x400x1)\n",
      "strides: [6400, 16, 1], [400, 1, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  convolution 0.5544 ms 100.0% \n",
      "  conv1x1_via_mm inf ms 0.0% \n",
      "SingleProcess AUTOTUNE benchmarking takes 0.0819 seconds and 0.0002 seconds precompiling for 2 choices\n",
      "E1116 07:07:17.334000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] Runtime error during autotuning: \n",
      "E1116 07:07:17.334000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4. \n",
      "E1116 07:07:17.334000 2074 site-packages/torch/_inductor/select_algorithm.py:2691] [6/3] Ignoring this choice.\n",
      "AUTOTUNE convolution(65536x320x16, 16x320x1)\n",
      "strides: [5120, 16, 1], [320, 1, 1]\n",
      "dtypes: torch.bfloat16, torch.bfloat16\n",
      "  convolution 0.4542 ms 100.0% \n",
      "  conv1x1_via_mm inf ms 0.0% \n",
      "SingleProcess AUTOTUNE benchmarking takes 0.0694 seconds and 0.0002 seconds precompiling for 2 choices\n",
      "ç”¨æˆ·æ‰¹æ¬¡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:59<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step4B] å®½çŸ©é˜µå¯¼å‡ºå®Œæˆï¼Œå†™å…¥äº† 29090 ä¸ªç”¨æˆ·ï¼Œæ–‡ä»¶è·¯å¾„ï¼šuser_asset_preferences_full_release.csv\n",
      "[Step4B] æœ€ç»ˆæ¨¡å‹æƒé‡ä¿å­˜è·¯å¾„ï¼šxdeepfm_fulldata_final.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 4B: å…¨é‡å¾®è°ƒ(1è½®) + å®½çŸ©é˜µå¯¼å‡ºï¼ˆå¼ºåˆ¶é‡å»º XDeepFM å®ä¾‹ç‰ˆï¼‰\n",
    "# ================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --------- å¯è°ƒè¶…å‚ ----------\n",
    "FINAL_EPOCHS = 1\n",
    "FINAL_LR = 5e-4\n",
    "FINAL_WEIGHT_DECAY = 1e-5\n",
    "FINAL_MODEL_PATH = \"xdeepfm_fulldata_final.pt\"\n",
    "\n",
    "FINAL_BATCH_SIZE_GPU = 1024\n",
    "FINAL_BATCH_SIZE_CPU = 128\n",
    "\n",
    "USER_BATCH_GPU = 256\n",
    "ITEM_BATCH_GPU = 256\n",
    "USER_BATCH_CPU = 128\n",
    "ITEM_BATCH_CPU = 128\n",
    "\n",
    "OUT_CSV = \"user_asset_preferences_full_release.csv\"\n",
    "BEST_PATH = globals().get(\"BEST_PATH\", \"xdeepfm_best.pt\")\n",
    "\n",
    "# --------- è®¾å¤‡ä¸ AMP ----------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_AMP = (DEVICE.type == \"cuda\")\n",
    "BF16_OK = (USE_AMP and torch.cuda.is_bf16_supported())\n",
    "AMP_DTYPE = torch.bfloat16 if BF16_OK else torch.float16\n",
    "print(f\"[Step4B] Device={DEVICE}; AMP={USE_AMP}; BF16_OK={BF16_OK}\")\n",
    "\n",
    "if USE_AMP:\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    cudnn.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# ============================================\n",
    "# 0) ç›´æ¥æŒ‰ Step2 é…ç½®é‡å»ºä¸€ä¸ªå…¨æ–°çš„ XDeepFM å®ä¾‹\n",
    "#    å®Œå…¨ä¸å†ç›¸ä¿¡åŸæ¥çš„ `model` å˜é‡ï¼Œé¿å… function æ±¡æŸ“\n",
    "# ============================================\n",
    "if \"XDeepFM\" not in globals():\n",
    "    raise RuntimeError(\"æœªæ‰¾åˆ° XDeepFM ç±»ï¼Œè¯·å…ˆè¿è¡Œ Step2 å®šä¹‰æ¨¡å‹ç±»ã€‚\")\n",
    "\n",
    "# æ ¹æ®ä½  Step2 çš„å†™æ³•ï¼Œé‡æ–°è®¡ç®— vocab / ç»´åº¦ä¿¡æ¯\n",
    "def _get_vocab_sizes(df: pd.DataFrame, cols: list) -> list:\n",
    "    return [int(df[c].max()) + 1 for c in cols]\n",
    "\n",
    "user_feats_sizes = _get_vocab_sizes(customers_latest, user_cat_features)\n",
    "asset_feats_sizes = _get_vocab_sizes(assets_latest, asset_cat_features)\n",
    "\n",
    "user_num = len(user2idx)\n",
    "asset_num = len(asset2idx)\n",
    "asset_num_feat_dim = len(num_cols)\n",
    "\n",
    "print(f\"[Step4B] é‡æ–°å®ä¾‹åŒ– XDeepFM...\")\n",
    "model = XDeepFM(\n",
    "    user_num=user_num,\n",
    "    asset_num=asset_num,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    user_feats_sizes=user_feats_sizes,\n",
    "    asset_feats_sizes=asset_feats_sizes,\n",
    "    asset_num_feat_dim=asset_num_feat_dim,\n",
    "    cin_sizes=CIN_SIZES,\n",
    "    dnn_hidden=DNN_HIDDEN,\n",
    "    dropout=DROPOUT,\n",
    "    emb_dropout=EMB_DROPOUT_DEFAULT,\n",
    "    base_pos_rate=None,\n",
    "    logit_sign=1,\n",
    ")\n",
    "print(f\"[Step4B] æ–° model ç±»å‹: {type(model)}\")\n",
    "\n",
    "# --------- é¿å…é‡å¤ torch.compile ----------\n",
    "try:\n",
    "    from torch._dynamo import is_compiled\n",
    "    already_compiled = is_compiled(model)\n",
    "except Exception:\n",
    "    already_compiled = False\n",
    "\n",
    "if USE_AMP and not already_compiled:\n",
    "    try:\n",
    "        model = torch.compile(model, mode=\"max-autotune\")\n",
    "        print(\"âœ… torch.compile enabled (Step4B)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ torch.compile failed (Step4B): {e}\")\n",
    "\n",
    "# --------- æƒé‡å®‰å…¨åŠ è½½ï¼ˆç°åœ¨ 100% ç¡®å®š model æ˜¯ nn.Module å®ä¾‹ï¼‰ ----------\n",
    "def load_state_safely(mdl: nn.Module, path: str):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[Step4B] æƒé‡æ–‡ä»¶ '{path}' ä¸å­˜åœ¨ï¼Œè·³è¿‡åŠ è½½ï¼ˆå°†ä»éšæœºåˆå§‹åŒ–æƒé‡å¼€å§‹å…¨é‡å¾®è°ƒï¼‰ã€‚\")\n",
    "        return\n",
    "    checkpoint = torch.load(path, map_location=\"cpu\")\n",
    "    if isinstance(checkpoint, dict):\n",
    "        if \"state_dict\" in checkpoint:\n",
    "            mdl.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "        else:\n",
    "            mdl.load_state_dict(checkpoint, strict=False)\n",
    "    elif isinstance(checkpoint, nn.Module):\n",
    "        mdl.load_state_dict(checkpoint.state_dict(), strict=False)\n",
    "    else:\n",
    "        mdl.load_state_dict(checkpoint, strict=False)\n",
    "    print(f\"[Step4B] æˆåŠŸåŠ è½½æƒé‡ '{path}'ã€‚\")\n",
    "\n",
    "load_state_safely(model, BEST_PATH)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# ============================================\n",
    "# DataLoader å·¥å‚\n",
    "# ============================================\n",
    "def build_dataloader(ds, batch_size, shuffle, gpu=False):\n",
    "    if gpu:\n",
    "        return DataLoader(ds, batch_size=batch_size, shuffle=shuffle,\n",
    "                          num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
    "    else:\n",
    "        return DataLoader(ds, batch_size=batch_size, shuffle=shuffle,\n",
    "                          num_workers=0, pin_memory=False, persistent_workers=False)\n",
    "\n",
    "def batch_to_device(batch, device):\n",
    "    non_blocking = (device.type == \"cuda\")\n",
    "    return tuple(t.to(device, non_blocking=non_blocking) for t in batch)\n",
    "\n",
    "# ============================================\n",
    "# 1) æ„å»ºå…¨é‡è®­ç»ƒé›†\n",
    "# ============================================\n",
    "print(\"[Step4B] æ„å»ºå…¨é‡è®­ç»ƒé›†...\")\n",
    "full_train_df = build_train_dataframe(pos_pairs, len(user2idx), len(asset2idx), NEG_SAMPLE_PER_POS)\n",
    "full_train_df = (\n",
    "    full_train_df\n",
    "    .merge(user_feat_df, left_on=\"user_idx\", right_index=True, how=\"left\")\n",
    "    .merge(asset_feat_df, left_on=\"asset_idx\", right_index=True, how=\"left\")\n",
    ")\n",
    "\n",
    "for c in num_cols:\n",
    "    full_train_df[c] = full_train_df[c].replace([np.inf, -np.inf, np.nan], 0.0)\n",
    "\n",
    "full_train_dataset = FARTransDataset(full_train_df, user_cat_features, asset_cat_features, num_cols)\n",
    "FINAL_BATCH_SIZE = FINAL_BATCH_SIZE_GPU if USE_AMP else FINAL_BATCH_SIZE_CPU\n",
    "full_train_loader = build_dataloader(full_train_dataset, FINAL_BATCH_SIZE, shuffle=True, gpu=USE_AMP)\n",
    "\n",
    "# ============================================\n",
    "# 2) ä¼°è®¡ pos_weight + 1 è½®å…¨é‡å¾®è°ƒ\n",
    "# ============================================\n",
    "LABEL_SMOOTH = 0.05\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_pos_weight(loader, sample_batches=10):\n",
    "    pos = neg = checked = 0\n",
    "    for batch in loader:\n",
    "        y = batch[-1]\n",
    "        y = torch.nan_to_num(y, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "        pos += int((y > 0.5).sum().item())\n",
    "        neg += int((y <= 0.5).sum().item())\n",
    "        checked += 1\n",
    "        if checked >= sample_batches:\n",
    "            break\n",
    "    pos, neg = max(pos, 1), max(neg, 1)\n",
    "    pw = neg / pos\n",
    "    print(f\"[Step4B ClassStats] pos={pos}, neg={neg}, pos_weightâ‰ˆ{pw:.2f}\")\n",
    "    return torch.tensor([pw], device=DEVICE, dtype=torch.float32)\n",
    "\n",
    "POS_WEIGHT = estimate_pos_weight(full_train_loader)\n",
    "\n",
    "try:\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=FINAL_LR,\n",
    "                                  weight_decay=FINAL_WEIGHT_DECAY, fused=USE_AMP)\n",
    "except TypeError:\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=FINAL_LR,\n",
    "                                  weight_decay=FINAL_WEIGHT_DECAY)\n",
    "\n",
    "scaler = torch.amp.GradScaler(enabled=USE_AMP)\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss, total_num = 0., 0\n",
    "    pbar = tqdm(full_train_loader, desc=\"FullData Train\", dynamic_ncols=True, leave=False)\n",
    "    for batch in pbar:\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=DEVICE.type, enabled=USE_AMP, dtype=AMP_DTYPE):\n",
    "            logits = model(*batch[:-1])\n",
    "            logits = torch.clamp(logits, -20, 20)\n",
    "            y = torch.nan_to_num(batch[-1], nan=0.0, posinf=1.0, neginf=0.0)\n",
    "            targets = y * (1.0 - LABEL_SMOOTH) + (1.0 - y) * LABEL_SMOOTH\n",
    "            per_sample = F.binary_cross_entropy_with_logits(\n",
    "                logits, targets, reduction=\"none\", pos_weight=POS_WEIGHT)\n",
    "            mask = torch.isfinite(per_sample)\n",
    "            loss = per_sample[mask].mean() if mask.any() else torch.tensor(0., device=DEVICE)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        n = int(mask.sum().item()) if mask.any() else 0\n",
    "        total_loss += float(loss.item()) * max(1, n)\n",
    "        total_num += max(1, n)\n",
    "        pbar.set_postfix(loss=total_loss / total_num)\n",
    "    return total_loss / total_num\n",
    "\n",
    "print(f\"\\n[Step4B] å…¨é‡å¾®è°ƒï¼Œè®­ç»ƒ {FINAL_EPOCHS} è½®...\")\n",
    "for epoch in range(FINAL_EPOCHS):\n",
    "    loss_epoch = train_one_epoch()\n",
    "    print(f\"[Step4B] Epoch {epoch+1}/{FINAL_EPOCHS} Loss {loss_epoch:.5f}\")\n",
    "\n",
    "torch.save(model.state_dict(), FINAL_MODEL_PATH)\n",
    "print(f\"[Step4B] å¾®è°ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³ {FINAL_MODEL_PATH}\")\n",
    "\n",
    "# ============================================\n",
    "# 3) å®½çŸ©é˜µæ¨ç†å¯¼å‡º CSV\n",
    "# ============================================\n",
    "model.eval()\n",
    "idx2user = {v: k for k, v in user2idx.items()}\n",
    "idx2asset = {v: k for k, v in asset2idx.items()}\n",
    "all_users_cat = customers_latest.set_index(\"user_idx\")[user_cat_features].sort_index()\n",
    "all_assets_cat_num = assets_latest.set_index(\"asset_idx\")[asset_cat_features + num_cols].sort_index()\n",
    "\n",
    "all_user_indices = np.arange(len(user2idx))\n",
    "all_asset_indices = np.arange(len(asset2idx))\n",
    "\n",
    "USER_BATCH = USER_BATCH_GPU if USE_AMP else USER_BATCH_CPU\n",
    "ITEM_BATCH = ITEM_BATCH_GPU if USE_AMP else ITEM_BATCH_CPU\n",
    "\n",
    "if os.path.exists(OUT_CSV):\n",
    "    os.remove(OUT_CSV)\n",
    "\n",
    "header = [\"customerID\"] + [idx2asset[int(i)] for i in all_asset_indices]\n",
    "pd.DataFrame([header]).to_csv(OUT_CSV, index=False, header=False)\n",
    "print(f\"[Step4B] å®½çŸ©é˜µè¡¨å¤´å†™å…¥ï¼Œå…± {len(header)} åˆ—ï¼ˆå« customerIDï¼‰\")\n",
    "\n",
    "total_users = 0\n",
    "print(\"[Step4B] å¼€å§‹æ¨ç†å¯¼å‡ºå®½çŸ©é˜µ...\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for start_u in tqdm(range(0, len(all_user_indices), USER_BATCH), desc=\"ç”¨æˆ·æ‰¹æ¬¡\"):\n",
    "        u_batch = all_user_indices[start_u:start_u+USER_BATCH].tolist()\n",
    "        U = len(u_batch)\n",
    "        user_idx_batch = torch.tensor(u_batch, dtype=torch.long, device=DEVICE)\n",
    "        user_cat_batch = torch.tensor(all_users_cat.loc[u_batch].values, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "        probs_blocks = []\n",
    "        for start_a in range(0, len(all_asset_indices), ITEM_BATCH):\n",
    "            a_batch = all_asset_indices[start_a:start_a+ITEM_BATCH].tolist()\n",
    "            A = len(a_batch)\n",
    "            asset_idx_batch = torch.tensor(a_batch, dtype=torch.long, device=DEVICE)\n",
    "            asset_cat_batch = torch.tensor(\n",
    "                all_assets_cat_num.loc[a_batch][asset_cat_features].values,\n",
    "                dtype=torch.long, device=DEVICE\n",
    "            )\n",
    "            asset_num_batch = torch.tensor(\n",
    "                all_assets_cat_num.loc[a_batch][num_cols].values,\n",
    "                dtype=torch.float32, device=DEVICE\n",
    "            )\n",
    "\n",
    "            user_expand_idx = user_idx_batch.unsqueeze(1).expand(-1, A).reshape(-1)\n",
    "            asset_expand_idx = asset_idx_batch.unsqueeze(0).expand(U, -1).reshape(-1)\n",
    "\n",
    "            user_cat_expand = user_cat_batch.unsqueeze(1).expand(-1, A, -1).reshape(-1, user_cat_batch.shape[1])\n",
    "            asset_cat_expand = asset_cat_batch.unsqueeze(0).expand(U, -1, -1).reshape(-1, asset_cat_batch.shape[1])\n",
    "            asset_num_expand = asset_num_batch.unsqueeze(0).expand(U, -1, -1).reshape(-1, asset_num_batch.shape[1])\n",
    "\n",
    "            with torch.amp.autocast(device_type=DEVICE.type, enabled=USE_AMP, dtype=AMP_DTYPE):\n",
    "                logits = model(user_expand_idx, user_cat_expand, asset_expand_idx, asset_cat_expand, asset_num_expand)\n",
    "                logits = torch.clamp(logits, -20, 20)\n",
    "                probs = torch.sigmoid(logits).to(torch.float32)\n",
    "\n",
    "            probs_chunk = probs.view(U, A).cpu().numpy()\n",
    "            probs_blocks.append(probs_chunk)\n",
    "\n",
    "        probs_full = np.concatenate(probs_blocks, axis=1)\n",
    "        df_chunk = pd.DataFrame(probs_full, columns=header[1:])\n",
    "        df_chunk.insert(0, \"customerID\", [idx2user[int(i)] for i in u_batch])\n",
    "        df_chunk.to_csv(OUT_CSV, mode=\"a\", index=False, header=False, float_format=\"%.6f\")\n",
    "        total_users += U\n",
    "\n",
    "print(f\"[Step4B] å®½çŸ©é˜µå¯¼å‡ºå®Œæˆï¼Œå†™å…¥äº† {total_users} ä¸ªç”¨æˆ·ï¼Œæ–‡ä»¶è·¯å¾„ï¼š{OUT_CSV}\")\n",
    "print(f\"[Step4B] æœ€ç»ˆæ¨¡å‹æƒé‡ä¿å­˜è·¯å¾„ï¼š{FINAL_MODEL_PATH}\")\n",
    "\n",
    "\n",
    "# NOTE:\n",
    "# å¯ç”¨ torch.compile + Inductor AUTOTUNE åï¼Œæ§åˆ¶å°ä¼šæ‰“å°ä¸€äº›\n",
    "# â€œRuntime error during autotuning ... Ignoring this choiceâ€ çš„ä¿¡æ¯ã€‚\n",
    "# è¿™äº›å¹¶ä¸æ˜¯è®­ç»ƒçœŸæ­£å¤±è´¥ï¼Œè€Œæ˜¯ PyTorch åœ¨æšä¸¾ Triton / ç¨€ç–ç®—å­\n",
    "# å€™é€‰å®ç°æ—¶ï¼Œå¯¹ä¸å…¼å®¹é…ç½®åšçš„å†…éƒ¨æ¢æµ‹å¹¶è‡ªåŠ¨ä¸¢å¼ƒã€‚\n",
    "# æœ€ç»ˆä¼šé€‰ç”¨ä¸€ä¸ªå…¼å®¹ä¸”æ€§èƒ½æœ€ä¼˜çš„å†…æ ¸ï¼Œå› æ­¤è¿™äº›æŠ¥é”™/è­¦å‘Šå¯ä»¥å®‰å…¨å¿½ç•¥ï¼Œ\n",
    "# ä¸å½±å“è®­ç»ƒæ”¶æ•›å’Œå¯¼å‡ºçš„åå¥½çŸ©é˜µç»“æœã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

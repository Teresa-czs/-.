{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63514f98-eecb-4885-8524-025eebcd9e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: E:\\科研\\深度学习框架--推荐系统\\user_item_purchase_matrix_full_latest_with_capacity.csv\n",
      "UserID column: 'customerID'\n",
      "Target column: 'investmentCapacity'\n",
      "Number of features: 806\n",
      "Unique classes in target: [0 1 2 3 4]\n",
      "Training samples: 20944, Validation samples: 2328, Test samples: 5818\n",
      "Training LightGBM model (quiet)...\n",
      "Evaluating on test data...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.58      0.66      3543\n",
      "           1       0.25      0.11      0.16      1097\n",
      "           2       0.35      0.27      0.30       953\n",
      "           3       0.07      0.36      0.12       157\n",
      "           4       0.03      0.49      0.06        68\n",
      "\n",
      "    accuracy                           0.43      5818\n",
      "   macro avg       0.29      0.36      0.26      5818\n",
      "weighted avg       0.57      0.43      0.48      5818\n",
      "\n",
      "Calculating feature importance...\n",
      "[警告] 无法写入 E:\\科研\\深度学习框架--推荐系统\\lgbm_shap_outputs\\feature_importance_original_order.csv（权限不足或被占用），改写入 E:\\科研\\深度学习框架--推荐系统\\lgbm_shap_outputs\\feature_importance_original_order_new.csv\n",
      "Saved original-order feature importance to E:\\科研\\深度学习框架--推荐系统\\lgbm_shap_outputs\\feature_importance_original_order.csv\n",
      "[警告] 无法写入 E:\\科研\\深度学习框架--推荐系统\\lgbm_shap_outputs\\feature_importance.csv（权限不足或被占用），改写入 E:\\科研\\深度学习框架--推荐系统\\lgbm_shap_outputs\\feature_importance_new.csv\n",
      "Saved sorted feature importance to E:\\科研\\深度学习框架--推荐系统\\lgbm_shap_outputs\\feature_importance.csv\n",
      "Saved feature importance plot.\n",
      "Computing SHAP values...\n",
      "Saved SHAP top features to E:\\科研\\深度学习框架--推荐系统\\lgbm_shap_outputs\\shap_top_features.csv\n",
      "【完成】所有结果保存在目录： E:\\科研\\深度学习框架--推荐系统\\lgbm_shap_outputs\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "\"\"\"\n",
    "LightGBM + SHAP 全流程分析示例（含兜底，静音版 + 保留原始项目顺序）\n",
    "- 修复多分类 SHAP 计算（支持 list / 3D ndarray）\n",
    "- 所有文件保存增加 PermissionError 兜底（自动改名 *_new.xxx）\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.ERROR)\n",
    "\n",
    "# ====== 依赖检查 ======\n",
    "required_libraries = [\n",
    "    (\"numpy\", \"np\"),\n",
    "    (\"pandas\", \"pd\"),\n",
    "    (\"sklearn\", \"sklearn\"),\n",
    "    (\"lightgbm\", \"lgb\"),\n",
    "    (\"matplotlib.pyplot\", \"plt\"),\n",
    "]\n",
    "missing_libraries = []\n",
    "for lib_name, _ in required_libraries:\n",
    "    try:\n",
    "        __import__(lib_name)\n",
    "    except ImportError:\n",
    "        missing_libraries.append(lib_name)\n",
    "if missing_libraries:\n",
    "    raise ImportError(f\"缺少必要的库，请安装：{', '.join(missing_libraries)}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"SimHei\", \"Microsoft YaHei\", \"Arial\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ====== SHAP 导入 ======\n",
    "try:\n",
    "    import shap\n",
    "\n",
    "    shap_available = True\n",
    "except Exception as e:\n",
    "    shap_available = False\n",
    "    print(f\"警告：SHAP 导入失败，将使用 LightGBM 兜底。原因：{e}\")\n",
    "\n",
    "# ====== 通用安全保存函数（处理 PermissionError） ======\n",
    "def _make_alt_path(path: str) -> str:\n",
    "    base, ext = os.path.splitext(path)\n",
    "    if not ext:\n",
    "        ext = \".txt\"\n",
    "    return f\"{base}_new{ext}\"\n",
    "\n",
    "def safe_to_csv(df: pd.DataFrame, path: str, **kwargs):\n",
    "    try:\n",
    "        df.to_csv(path, **kwargs)\n",
    "    except PermissionError:\n",
    "        alt_path = _make_alt_path(path)\n",
    "        print(f\"[警告] 无法写入 {path}（权限不足或被占用），改写入 {alt_path}\")\n",
    "        df.to_csv(alt_path, **kwargs)\n",
    "\n",
    "def safe_write_text(path: str, text: str, mode: str = \"w\", encoding: str = \"utf-8\"):\n",
    "    try:\n",
    "        with open(path, mode, encoding=encoding) as f:\n",
    "            f.write(text)\n",
    "    except PermissionError:\n",
    "        alt_path = _make_alt_path(path)\n",
    "        print(f\"[警告] 无法写入 {path}（权限不足或被占用），改写入 {alt_path}\")\n",
    "        with open(alt_path, mode, encoding=encoding) as f:\n",
    "            f.write(text)\n",
    "\n",
    "def safe_save_fig(path: str):\n",
    "    try:\n",
    "        plt.savefig(path)\n",
    "    except PermissionError:\n",
    "        alt_path = _make_alt_path(path)\n",
    "        print(f\"[警告] 无法写入图片 {path}（权限不足或被占用），改写入 {alt_path}\")\n",
    "        plt.savefig(alt_path)\n",
    "\n",
    "# ====== 配置 ======\n",
    "DATA_PATH = r\"E:\\科研\\深度学习框架--推荐系统\\user_item_purchase_matrix_full_latest_with_capacity.csv\"\n",
    "RANDOM_SEED = 42\n",
    "TEST_RATIO = 0.2\n",
    "VALID_RATIO = 0.1\n",
    "N_ESTIMATORS = 2000\n",
    "EARLY_STOPPING_ROUNDS = 100\n",
    "TOP_N = 50\n",
    "\n",
    "OUTPUT_DIR = os.path.join(os.path.dirname(DATA_PATH), \"lgbm_shap_outputs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ====== 读取数据 ======\n",
    "print(\"Loading data from:\", DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "\n",
    "user_id_col = df.columns[0]\n",
    "target_col = df.columns[-1]\n",
    "feature_cols = df.columns[1:-1]\n",
    "\n",
    "print(f\"UserID column: '{user_id_col}'\")\n",
    "print(f\"Target column: '{target_col}'\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "\n",
    "X_df = df[feature_cols].copy()\n",
    "y_raw = df[target_col]\n",
    "\n",
    "# 特征预处理：统一为 0/1 的 uint8\n",
    "for c in feature_cols:\n",
    "    X_df[c] = pd.to_numeric(X_df[c], errors=\"coerce\").fillna(0)\n",
    "    X_df[c] = X_df[c].clip(0, 1).astype(np.uint8)\n",
    "\n",
    "# 目标编码\n",
    "if y_raw.dtype.kind in \"bifc\":\n",
    "    y = y_raw.astype(int).values\n",
    "else:\n",
    "    y, _ = pd.factorize(y_raw)\n",
    "\n",
    "classes = np.unique(y)\n",
    "print(f\"Unique classes in target: {classes}\")\n",
    "\n",
    "# ====== 划分训练 / 验证 / 测试 ======\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_df, y, test_size=TEST_RATIO, stratify=y, random_state=RANDOM_SEED\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=VALID_RATIO,\n",
    "    stratify=y_train_full,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "# 类别权重\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "sample_weights = np.array([class_weight_dict[cls] for cls in y_train])\n",
    "\n",
    "print(\n",
    "    f\"Training samples: {X_train.shape[0]}, \"\n",
    "    f\"Validation samples: {X_valid.shape[0]}, \"\n",
    "    f\"Test samples: {X_test.shape[0]}\"\n",
    ")\n",
    "\n",
    "# ====== LightGBM 模型训练 ======\n",
    "is_multiclass = len(np.unique(y)) > 2\n",
    "params = {\n",
    "    \"objective\": \"multiclass\" if is_multiclass else \"binary\",\n",
    "    \"random_state\": RANDOM_SEED,\n",
    "    \"n_estimators\": N_ESTIMATORS,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 63,\n",
    "    \"verbose\": -1,\n",
    "    \"n_jobs\": -1,\n",
    "    \"metric\": \"multi_logloss\" if is_multiclass else \"binary_logloss\",\n",
    "}\n",
    "if is_multiclass:\n",
    "    params[\"num_class\"] = len(np.unique(y))\n",
    "\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "print(\"Training LightGBM model (quiet)...\")\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    sample_weight=sample_weights,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_metric=\"multi_logloss\" if is_multiclass else \"logloss\",\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(EARLY_STOPPING_ROUNDS, verbose=False),\n",
    "        lgb.log_evaluation(0),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# ====== 测试集评估 ======\n",
    "print(\"Evaluating on test data...\")\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "report_path = os.path.join(OUTPUT_DIR, \"classification_report.txt\")\n",
    "safe_write_text(report_path, report, encoding=\"utf-8\")\n",
    "\n",
    "# ====== 特征重要性（Gain） ======\n",
    "print(\"Calculating feature importance...\")\n",
    "importance_gain = model.booster_.feature_importance(importance_type=\"gain\")\n",
    "importance_split = model.booster_.feature_importance(importance_type=\"split\")\n",
    "feat_names = np.array(feature_cols)\n",
    "\n",
    "# 保留原始顺序\n",
    "imp_df_original = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": feat_names,\n",
    "        \"importance_gain\": importance_gain,\n",
    "        \"importance_split\": importance_split,\n",
    "    }\n",
    ")\n",
    "orig_path = os.path.join(OUTPUT_DIR, \"feature_importance_original_order.csv\")\n",
    "safe_to_csv(imp_df_original, orig_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved original-order feature importance to {orig_path}\")\n",
    "\n",
    "# 按 Gain 降序排列\n",
    "imp_df = imp_df_original.sort_values(\"importance_gain\", ascending=False)\n",
    "imp_path = os.path.join(OUTPUT_DIR, \"feature_importance.csv\")\n",
    "safe_to_csv(imp_df, imp_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved sorted feature importance to {imp_path}\")\n",
    "\n",
    "# Top N 条形图\n",
    "top_imp = imp_df.head(TOP_N)\n",
    "plt.figure(figsize=(10, max(6, TOP_N * 0.25)))\n",
    "plt.barh(top_imp[\"feature\"][::-1], top_imp[\"importance_gain\"][::-1])\n",
    "plt.title(f\"Top {TOP_N} Feature Importance (Gain)\")\n",
    "plt.xlabel(\"Importance Gain\")\n",
    "plt.tight_layout()\n",
    "fig_path = os.path.join(OUTPUT_DIR, \"feature_importance_top50.png\")\n",
    "safe_save_fig(fig_path)\n",
    "plt.close()\n",
    "print(\"Saved feature importance plot.\")\n",
    "\n",
    "# ====== 准备 SHAP 采样数据 ======\n",
    "print(\"Computing SHAP values...\")\n",
    "sample_size = min(5000, X_train.shape[0])\n",
    "sample_indices = np.random.choice(X_train.index, sample_size, replace=False)\n",
    "X_sample = X_train.loc[sample_indices]\n",
    "\n",
    "# ====== 辅助函数 ======\n",
    "def mean_abs_shap(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"对每个特征计算 mean(|SHAP|)。输入必须为 (n_samples, n_features)\"\"\"\n",
    "    return np.mean(np.abs(arr), axis=0)\n",
    "\n",
    "\n",
    "def build_top_df(mean_abs: np.ndarray, features: np.ndarray, top_k: int = TOP_N, cls_name=None):\n",
    "    \"\"\"根据 mean(|SHAP|) 构建 Top 特征 DataFrame\"\"\"\n",
    "    idx = np.argsort(-mean_abs)\n",
    "    df_top = pd.DataFrame(\n",
    "        {\n",
    "            \"feature\": features[idx][:top_k],\n",
    "            \"mean_abs_shap\": mean_abs[idx][:top_k],\n",
    "        }\n",
    "    )\n",
    "    if cls_name is not None:\n",
    "        df_top.insert(0, \"class\", cls_name)\n",
    "    return df_top\n",
    "\n",
    "\n",
    "def to_classwise_shap_list(shap_values_raw, n_samples, n_features, n_classes):\n",
    "    \"\"\"\n",
    "    将 shap_values 统一转成：\n",
    "        [array(shape=(n_samples, n_features)), ...]  长度 = n_classes\n",
    "\n",
    "    支持：\n",
    "    - list: [ (n_samples, n_features), ... ]\n",
    "    - 3D ndarray: 维度可能是 (n_samples, n_classes, n_features)、\n",
    "                  (n_samples, n_features, n_classes)、\n",
    "                  (n_classes, n_samples, n_features) 等。\n",
    "    \"\"\"\n",
    "    # 已经是按类别 list 的情况\n",
    "    if isinstance(shap_values_raw, list):\n",
    "        if len(shap_values_raw) != n_classes:\n",
    "            raise ValueError(\n",
    "                f\"SHAP 返回 list，但长度 {len(shap_values_raw)} \"\n",
    "                f\"与类别数 {n_classes} 不一致\"\n",
    "            )\n",
    "        # 每个元素应为 (n_samples, n_features)\n",
    "        for arr in shap_values_raw:\n",
    "            if not isinstance(arr, np.ndarray) or arr.ndim != 2:\n",
    "                raise ValueError(\"list 中每个 shap 数组必须是二维 ndarray\")\n",
    "        return shap_values_raw\n",
    "\n",
    "    # ndarray 情况\n",
    "    if not isinstance(shap_values_raw, np.ndarray):\n",
    "        raise ValueError(f\"无法处理的 shap_values 类型: {type(shap_values_raw)}\")\n",
    "\n",
    "    if shap_values_raw.ndim == 2:\n",
    "        # 2D 的情况（有些版本二分类会这样），复制成每类一份\n",
    "        if shap_values_raw.shape != (n_samples, n_features):\n",
    "            raise ValueError(\n",
    "                f\"二维 shap_values 的形状 {shap_values_raw.shape} \"\n",
    "                f\"与 (n_samples, n_features)=({n_samples}, {n_features}) 不一致\"\n",
    "            )\n",
    "        return [shap_values_raw for _ in range(n_classes)]\n",
    "\n",
    "    if shap_values_raw.ndim == 3:\n",
    "        # 自动识别哪一维是 samples / classes / features\n",
    "        s = shap_values_raw.shape\n",
    "        try:\n",
    "            ax_samples = [i for i in range(3) if s[i] == n_samples][0]\n",
    "            ax_classes = [i for i in range(3) if s[i] == n_classes and i != ax_samples][0]\n",
    "            ax_features = [\n",
    "                i\n",
    "                for i in range(3)\n",
    "                if s[i] == n_features and i not in (ax_samples, ax_classes)\n",
    "            ][0]\n",
    "        except IndexError:\n",
    "            raise ValueError(\n",
    "                f\"无法根据形状 {s} 匹配 (n_samples={n_samples}, \"\n",
    "                f\"n_classes={n_classes}, n_features={n_features})\"\n",
    "            )\n",
    "\n",
    "        # 重排为 (n_classes, n_samples, n_features)\n",
    "        shap_reordered = np.moveaxis(\n",
    "            shap_values_raw, [ax_classes, ax_samples, ax_features], [0, 1, 2]\n",
    "        )\n",
    "        # 按类别拆分，每个 (n_samples, n_features)\n",
    "        return [shap_reordered[c, :, :] for c in range(n_classes)]\n",
    "\n",
    "    raise ValueError(f\"不支持的 shap_values 维度: {shap_values_raw.ndim}\")\n",
    "\n",
    "\n",
    "shap_top_df = None\n",
    "\n",
    "# ====== 优先使用 SHAP，失败再兜底 ======\n",
    "if shap_available:\n",
    "    try:\n",
    "        # 对树模型用 TreeExplainer 更快\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values_raw = explainer.shap_values(\n",
    "            X_sample, check_additivity=False  # 防止部分版本出现 additivity warning/error\n",
    "        )\n",
    "\n",
    "        if is_multiclass:\n",
    "            # 多分类：统一转成 [ (n_samples, n_features) ] 的列表\n",
    "            n_samples, n_features = X_sample.shape\n",
    "            n_classes = len(classes)\n",
    "            shap_values_per_class = to_classwise_shap_list(\n",
    "                shap_values_raw, n_samples, n_features, n_classes\n",
    "            )\n",
    "\n",
    "            # 画第一个类别的 summary plot（可按需改成循环）\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_values_per_class[0], X_sample, show=False)\n",
    "            plt.tight_layout()\n",
    "            shap_fig_path = os.path.join(OUTPUT_DIR, \"shap_summary.png\")\n",
    "            safe_save_fig(shap_fig_path)\n",
    "            plt.close()\n",
    "\n",
    "            # 计算每个类别的 Top 特征\n",
    "            dfs = []\n",
    "            for cls_idx, cls_name in enumerate(classes):\n",
    "                mean_abs = mean_abs_shap(shap_values_per_class[cls_idx])\n",
    "                dfs.append(build_top_df(mean_abs, feat_names, cls_name=cls_name))\n",
    "            shap_top_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            # 二分类 / 回归：确保是 2D\n",
    "            if isinstance(shap_values_raw, list):\n",
    "                shap_values_2d = shap_values_raw[0]\n",
    "            else:\n",
    "                shap_values_2d = shap_values_raw\n",
    "\n",
    "            if not isinstance(shap_values_2d, np.ndarray) or shap_values_2d.ndim != 2:\n",
    "                raise ValueError(f\"二分类 SHAP 形状异常: {type(shap_values_2d)}, ndim={shap_values_2d.ndim}\")\n",
    "\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_values_2d, X_sample, show=False)\n",
    "            plt.tight_layout()\n",
    "            shap_fig_path = os.path.join(OUTPUT_DIR, \"shap_summary.png\")\n",
    "            safe_save_fig(shap_fig_path)\n",
    "            plt.close()\n",
    "\n",
    "            mean_abs = mean_abs_shap(shap_values_2d)\n",
    "            shap_top_df = build_top_df(mean_abs, feat_names)\n",
    "\n",
    "    except Exception as e:\n",
    "        shap_available = False\n",
    "        print(f\"SHAP 计算出错，改用 LightGBM 兜底：{e}\")\n",
    "\n",
    "# ====== 如果 SHAP 不可用 / 失败，使用 pred_contrib 兜底 ======\n",
    "if not shap_available:\n",
    "    raw_contrib = model.booster_.predict(\n",
    "        X_sample, pred_contrib=True, num_iteration=model.best_iteration_\n",
    "    )\n",
    "    n_samples = X_sample.shape[0]\n",
    "    n_features = len(feat_names)\n",
    "    n_classes = len(classes) if is_multiclass else 1\n",
    "\n",
    "    if is_multiclass:\n",
    "        # LightGBM multi-class pred_contrib 输出形状一般为 (n_samples, n_classes * (n_features + 1))\n",
    "        raw_contrib = raw_contrib.reshape(n_samples, n_classes, n_features + 1)\n",
    "        dfs = []\n",
    "        for cls_idx, cls_name in enumerate(classes):\n",
    "            contrib_cls = raw_contrib[:, cls_idx, :-1]  # 去掉 bias 项\n",
    "            dfs.append(\n",
    "                build_top_df(mean_abs_shap(contrib_cls), feat_names, cls_name=cls_name)\n",
    "            )\n",
    "        shap_top_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        # 画第一个类别的 TopN 作为可视化\n",
    "        plt.figure(figsize=(10, max(6, TOP_N * 0.25)))\n",
    "        subset = dfs[0].head(TOP_N)\n",
    "        plt.barh(subset[\"feature\"][::-1], subset[\"mean_abs_shap\"][::-1])\n",
    "        plt.title(f\"Top {TOP_N} SHAP (pred_contrib fallback, class={classes[0]})\")\n",
    "        plt.xlabel(\"Mean |SHAP|\")\n",
    "        plt.tight_layout()\n",
    "        shap_fig_path = os.path.join(OUTPUT_DIR, \"shap_summary.png\")\n",
    "        safe_save_fig(shap_fig_path)\n",
    "        plt.close()\n",
    "\n",
    "    else:\n",
    "        contrib = raw_contrib[:, :-1]  # 去掉 bias\n",
    "        mean_abs = mean_abs_shap(contrib)\n",
    "        shap_top_df = build_top_df(mean_abs, feat_names)\n",
    "\n",
    "        plt.figure(figsize=(10, max(6, TOP_N * 0.25)))\n",
    "        subset = shap_top_df.head(TOP_N)\n",
    "        plt.barh(subset[\"feature\"][::-1], subset[\"mean_abs_shap\"][::-1])\n",
    "        plt.title(f\"Top {TOP_N} SHAP (pred_contrib fallback)\")\n",
    "        plt.xlabel(\"Mean |SHAP|\")\n",
    "        plt.tight_layout()\n",
    "        shap_fig_path = os.path.join(OUTPUT_DIR, \"shap_summary.png\")\n",
    "        safe_save_fig(shap_fig_path)\n",
    "        plt.close()\n",
    "\n",
    "# ====== 保存 SHAP Top 特征 ======\n",
    "shap_top_path = os.path.join(OUTPUT_DIR, \"shap_top_features.csv\")\n",
    "safe_to_csv(shap_top_df, shap_top_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved SHAP top features to {shap_top_path}\")\n",
    "print(\"【完成】所有结果保存在目录：\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ebe58-ee67-4646-91cb-e4c6e5aa7291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
